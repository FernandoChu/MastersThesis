\documentclass[../main.tex]{subfiles}
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introducción}
En la actualidad, la mayoría de las matemáticas está basada en teoría de conjuntos \cite{cantor_uber_1874}, {\color{red} completar}.
Así, se pueden construir a los n\'umeros reales como cortes de Dedekind de los racionales; los cuales, a su vez, son clases de equivalencias de los enteros, que se construyen a partir de los naturales, y estos finalmente pueden ser definidos en términos puramente de conjuntos,{\color{red} como puede ser visto en Rudin []}.

Sin embargo, este procedimiento se da en realidad en dos niveles distintos.
En el primero, el puramente l\'ogico, los objetos de análisis son las proposiciones, y las reglas de la lógica indican qué inferencias y deducciones son correctas {\color{red} al asumir} ciertas hipótesis {\color{red} como verdaderas}.
En el segundo, los objetos de estudio son los conjuntos, y son los axiomas de la teoría de conjuntos los que permiten definir qué operación o relación está bien definida.
Nótese que estos dos niveles están completamente separados: la lógica sola no puede razonar sobre la teoría de conjuntos (o cualquier otra teoría), mientras que la teoría de conjuntos sola no puede razonar sobre proposiciones o inferencias lógicas.

En contraste, la teoría de tipos dependientes unifica estos dos constructos, las proposiciones y los conjuntos, y solo usa una noción central, la de \lq\lq tipos\rq\rq. ``tipos''
Así, podemos expresar diversas proposiciones, por ejemplo, que existe el tipo de los reales ($\cdot \vdash \R : \mathcal U_i$), o que $\pi$ es un elemento de este tipo ($\cdot \vdash \pi :\R$).
También tendremos que las proposiciones mismas pueden ser representadas por un tipo, con expresiones como $\cdot \vdash p : 3^2=9$ dando a entender que $p$ es una demostración de que $3^2=9$.

Además de tener una mayor simplicidad teórica, existen múltiples ventajas de esta nueva teoría, mencionaremos ahora dos. Primero, permite formalizar algunos conceptos que intuitivamente deberían de existir y, sin embargo, son imposibles de formalizar en teoría de conjuntos.
Por ejemplo, la función identidad universal, aplicable a cualquier conjunto, no está bien definida puesto que su ``conjunto’’ de dominio y de llegada es la colección de todos los conjuntos, y este no es un conjunto, sino una clase propia.

Segundo, y más importante aún, es qué las proposiciones y las demostraciones se vuelven también objetos de estudio en el mismo nivel que otras estructuras matemáticas, como los grupos o los espacios vectoriales, por lo que se pueden analizar y manipular como es común en otras áreas de estudio.
Esto será vital para la interpretación homotópica que detallaremos en la Sección 2, en donde una demostración de que $a=b$ se interpretará como un camino en cierto espacio topológico.

A continuación daremos una descripción formal y rigurosa de la teoría de tipos dependientes (DTT, en adelante, por sus siglas en inglés), haciendo comparación a la Matemática Clásica (MC, en adelante) cuando sea conveniente.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Expresiones, términos y contextos}
Dado que las proposiciones y las demostraciones son objetos mismos en DTT, es necesario tener mayor precisión respecto a los significados de ciertos términos.
\begin{definition}
    Una \textbf{signatura} $Sg$ es una colección de símbolos tipográficos. Una \textbf{expresión} $Exp_{Sg}$ es una secuencia finita de símbolos provenientes de la signatura $Sg$.
\end{definition}
\begin{example}
    La MC utiliza como signatura la colección que contiene a los caracteres alfanum\'ericos, los conectores l\'ogicos y a los operadores; es decir:
    {\color{red} $$Sg=\{\textrm\lq1\textrm\rq,\textrm\lq(\textrm',\textrm\lqn\textrm',\textrm\lq{+}\textrm',\textrm\lq\Sigma\textrm',\textrm`x_i\textrm',\dots\}$$}
    Una expresión t\'ipica {\color{red}de MC} es $\langle \textrm`1\textrm', \textrm`{+}\textrm', \textrm`1\textrm', \textrm`{=}\textrm', \textrm`2\textrm' \rangle_{Sg}$.
\end{example}
\begin{notation}
    Asumiremos siempre que esta misma signatura está implícita en todas las próximas expresiones que escribamos. Además, las expresiones se escribirán sin comillas, sin corchetes y sin hacer referencia a esta signatura.
\end{notation}
\begin{justification}
    {\color{red} Puesto que la signatura ser\'a la misma para el resto de este documento y dado que existe una sola forma de interpretar una expresión simplificada como una secuencia de caracteres, no habr\'a riesgo de ambigüedad.}
\end{justification}
La justificación de esta notación es simple, pero se ha dado para enfatizar que \textit{alguna} justificación es necesaria. En las próximas notaciones, omitiremos las justificaciones triviales y solo justificaremos las más complicadas de realizar.

\begin{definition}
    Dada una expresión de la forma\footnote{En la expresión $((a):(A))$, se entiende que $a$ no es el s\'imbolo {\color{red}$\lq a \rq$}, sino una meta-variable que puede tomar como valor cualquier expresión. Lo mismo aplica para $A$. Utilizaremos meta-variables sin mencionar que lo son, dejando la tarea de discernirlas  al lector. {\color{red} Hay que dejar en claro que es una meta-variable}} $((a):(A))$, donde el símbolo `${\equiv} \textrm'$ no es parte de $a$, diremos que $A$ es un \textbf{tipo} y que $a$ es un \textbf{término} de tipo $A$.
\end{definition}
\begin{example}
    En la expresión $((2+n):(\N))$, $\N$ es un tipo y que $({\color{red}2}+n)$ es un término de tipo $\N$.
\end{example}
\begin{notation}
    En la mayor\'ia de casos, omitiremos los paréntesis, entendiendo que el símbolo `${:}\textrm'$ tiene menor precedencia que otros símbolos por introducir, a excepción de los símbolos `${,}\textrm'$ (en contextos), y `${\vdash}\textrm'$ y  `${\textnormal{ctx}}\textrm'$ (en juicios).
\end{notation}
{\color{red}
\begin{definition}[Meta-variable]...
\end{definition}
}
Existen ciertas semejanzas entre $a:A$ en DTT y $a \in A$ en MC, pero también hay algunas diferencias importantes.
Primero, $a$ no es un elemento que existe independientemente de $A$; es decir, un término siempre debe estar acompañado del tipo al que corresponde.
Relacionado a esto, un término pertenece únicamente a un tipo (con una excepción, ver Sección \ref{universes}), mientras que en teoría de conjuntos un elemento puede pertenecer a varios conjuntos.

\begin{definition}
    Un \textbf{contexto} {\color{red} que usualmente lo denotaremos por  los s\'imbolos $\Gamma$ o $\Delta$}, es una lista  {\color{red} finita} de expresiones de la forma $a:A$. Es decir, un contexto es una expresión de la forma:
    {\color{red} $$\langle x_1{:}A_1,\,x_2{:}A_2,\, \dots,\, x_n{:}A_n\rangle$$}
    {\color{red} Donde los $x_i$ son llamados \textbf{variables} y en un contexto estas variables deben de ser distintas}
\end{definition}
\begin{example}
    La expresión $\langle n{:}\N,\,v{:}\R^n,\,M{:}\R^{n\times n},\, Mv{:}\R^n \rangle$ es un contexto.
\end{example}
\begin{notation}
    Omitiremos siempre los corchetes, entendiendo que los símbolos `${,}\textrm'$ en la lista tienen menor precedencia que otros símbolos por introducir, a excepción de los símbolos `${\vdash}\textrm'$ y  `${\textnormal{ctx}}\textrm'$ en juicios. Además, denotamos el contexto vac\'io con el símbolo `$ {\cdot}\textrm\rq$.
\end{notation}

N\'otese que las expresiones y los contextos pueden no estar bien formadas; es decir, pueden ser una secuencia de símbolos sin significado alguno, como $\int 0/0 : \sin \Q$.
Los juicios evitan este problema.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Juicios y reglas de inferencia}
\begin{definition}
    Sea $\Gamma$ es un contexto, un \textbf{juicio} es una expresión de una de las tres siguientes formas:
    $$(\Gamma) \textnormal{ ctx} \hspace{4em}  (\Gamma) \vdash (a:A) \hspace{4em}  (\Gamma) \vdash (a\equiv a':A)$$
\end{definition}
\begin{notation}
    Omitiremos siempre los paréntesis, entendiendo que los símbolos `${\vdash}\textrm'$ y `${\textnormal{ctx}}\textrm'$ tienen menor precedencia que todos los otros símbolos. En el caso de los últimos dos tipos de juicios, omitiremos la mención del contexto $\Gamma$ y el símbolo $\vdash$ cuando el contexto no sea relevante o este implícito.
\end{notation}

La noción de juicios en DTT toma un rol similar al de proposiciones en MC. El significado de estos juicios es detallado en el siguiente cuadro.
\begin{table}[H]
    \begin{center}
        \begin{tabular}{ l l }
            \thickhline
            Juicio                       & Significado                                                                                                 \\
            \hline
            $\Gamma \text{ ctx}$         & \parbox[t]{9cm}{\begin{spacing}{1}
                                                                   $\Gamma$ es un contexto bien formado; es decir, una lista de suposiciones bien formadas.
                                                               \end{spacing}}     \\[1.4em]
            $\Gamma \vdash a:A$          & \parbox[t]{9cm}{\begin{spacing}{1}
                                                                   El contexto $\Gamma$ implica que $a$ es un elemento del tipo $A$.
                                                               \end{spacing}}                            \\[.3em]
            $\Gamma \vdash a\equiv a':A$ & \parbox[t]{9cm}{\begin{spacing}{1}
                                                                   El contexto $\Gamma$ implica que $a$ y $a'$ son objetos iguales por definición del tipo $A$.
                                                               \end{spacing}} \\
            \thickhline                                                                                                                                \\[-2.4em]
        \end{tabular}
    \end{center}
    \caption{Juicios en DTT y su significado.}
    \label{table:1}
\end{table}

Notamos que el tercer tipo de juicios se refiere solo a igualdades por definición, en la Sección \ref{idtype} introduciremos otra noción de igualdad. Por otro lado, los primeros dos juicios formalizan la noción de que una expresión tenga ``sentido''.

\begin{definition}
    Una expresión de la forma $a$ se dice \textbf{bien tipada} si es que existe un contexto $\Gamma$ y un tipo $A$ tal que {\color{red} \lq\lq $\Gamma \text{ ctx}$\rq\rq  y \lq\lq$\Gamma \vdash a:A$\rq\rq.\\
        }
    Similarmente, una expresi\'on de la forma $b:B$ se dice \textbf{bien tipada} si es que existe un contexto $\Gamma$ tal que $\Gamma \text{ ctx}$ y $\Gamma \vdash \color{red}b:B$.
\end{definition}

De esta manera, veremos que la expresión previa, $\int 0/0 : \sin \Q$, no est\'a bien tipada.
Para llegar a esta conclusi\'on, debemos entender el proceso a través del cual llegamos a estos juicios: la aplicación de reglas de inferencia.

\begin{definition}
    Una \textbf{regla de inferencia} es de la forma
    \begin{prooftree}
        \AxiomC{$\mathcal H_1$}
        \AxiomC{$\cdots$}
        \AxiomC{$\mathcal H_k$} \RightLabel{\footnotesize{NOMBRE}}
        \TrinaryInfC{$\mathcal C$}
    \end{prooftree}
    donde $\mathcal H_1, \dots, \mathcal H_k$ y $\mathcal C$ son expresiones. Las expresiones $\mathcal H_1, \dots, \mathcal H_k$ son llamadas \textbf{hipótesis}, mientras que $\mathcal C$ es llamada la \textbf{conclusión}.
\end{definition}

Escribimos a la derecha el nombre de la regla, para ser referenciada posteriormente.
Cabe notar que una regla puede tener restricciones adicionales que deben ser corroboradas antes de poder ser aplicada.
Si la lista de hipótesis es muy larga, las apilaremos unas sobre otras (ver Reglas \ref{coprodelim}).
Las reglas toman un rol similar al de la deducci\'on l\'ogica en MC.

\begin{definition}
    Una \textbf{derivación} de un juicio es un árbol invertido con el juicio por derivar en la raíz del árbol, donde el paso de un nodo a otro nodo está justificado por una regla de inferencia.
\end{definition}

\begin{example}
    Con las reglas que presentaremos posteriormente, el siguiente árbol es una derivación de $\cdot \vdash \textbf{0} + \textbf{1} : \mathcal{U}_0$.
    \begin{prooftree}
        \def\ScoreOverhang{1pt} \def\extraVskip{3pt}  \def\defaultHypSeparation{\hskip .5in}
        \AxiomC{}\RightLabel{\footnotesize ctx-EMP}
        \UnaryInfC{$\cdot$ ctx} \RightLabel{\footnotesize{$0$-FORM}}
        \UnaryInfC{$\cdot \vdash \textbf{0} : \mathcal{U}_0$}
        \AxiomC{}\RightLabel{\footnotesize ctx-EMP}
        \UnaryInfC{$\cdot$ ctx} \RightLabel{\footnotesize{$1$-FORM}}
        \UnaryInfC{$\cdot \vdash \textbf{1} : \mathcal{U}_0$} \RightLabel{\footnotesize $+$-FORM}
        \BinaryInfC{$\cdot \vdash \textbf{0} + \textbf{1} : \mathcal{U}_0$}
    \end{prooftree}
\end{example}

Con los conceptos previos ya definidos, comenzaremos a introducir las reglas de inferencias de DTT.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Universos} \label{universes}
Como mencionamos previamente, todo término es un elemento de un tipo.
Para ser manipulados efectivamente, estos, a su vez, son elementos de otro tipo.
\begin{definition}
    El tipo de un tipo es llamado un \textbf{universo}.
\end{definition}
A fin de evitar la paradoja de Russell, un universo no es un elemento de sí mismo. {\color{red} Describir brevemente la paradoja de Russell}
Al contrario, existe una infinita jerarquía de universos, la cual se ver\'a formalizada en las siguientes reglas.
\begin{rules}
    (Reglas b\'asicas de universos)
    \begin{center}
        \AxiomC{$\Gamma$ ctx}\RightLabel{\footnotesize  $\mathcal{U}_i$-INTRO}
        \UnaryInfC{$\Gamma \vdash  \mathcal{U}_i:  \mathcal{U}_{i+1}$}  \DisplayProof \hspace{3em}
        \AxiomC{$\Gamma \vdash  A:  \mathcal{U}_{i}$}\RightLabel{\footnotesize  $\mathcal{U}_i$-CUMUL}
        \UnaryInfC{$\Gamma \vdash  A :  \mathcal{U}_{i+1}$}  \DisplayProof
    \end{center}
\end{rules}

La primera regla indica que si $\Gamma$ es un contexto bien formado, entonces $\Gamma$ implica que el universo $\mathcal{U}_i$ es un elemento del universo $\mathcal{U}_{i+1}$.
La segunda regla indica que si $\Gamma$ implica que $A$ es un elemento del universo $\mathcal{U}_{i}$, entonces $\Gamma$ implica que $A$ también es un elemento del universo $\mathcal{U}_{i+1}$.

Dado que son las primeras reglas introducidas, hemos brindado una {\color{red}interpretaci\'on} de ellas.
Para las próximas reglas no realizaremos este tipo de comentarios, salvo para aclarar alguna posible confusión.
La lista completa de reglas se encuentra en el Apéndice \ref{reglas}.

\begin{notation}
    Omitiremos los subíndices de los universos en la mayoría de escenarios, por lo que interpretaremos expresiones sin sentido como $\mathcal U: \mathcal U$ agregando índices adecuados, obteniendo $\mathcal{U}_i: \mathcal{U}_{i+1}$.
    Esta práctica puede traer inconsistencias si no es manejada con precisión, pero la usaremos igualmente para reducir la carga notacional.
\end{notation}

Nótese que los subíndices no son elementos del tipo de los naturales, sino son parte del símbolo `$\mathcal U_i\textrm'$; es decir, este es un símbolo básico.
Por este motivo, expresiones como $n{:}\N \vdash A: \mathcal U_n$ no están bien formadas.

Con los universos ya definidos, introducimos las reglas respecto a la formación de contextos.

\begin{rules}
    (Reglas b\'asicas de contextos y variables)
    \begin{center}
        \AxiomC{}\RightLabel{\footnotesize ctx-EMP}
        \UnaryInfC{$\cdot$ ctx} \DisplayProof \hspace{3em}
        \AxiomC{$x_1{:}A_1, \dots,x_{n-1}{:}A_{n-1} \vdash A_n:\mathcal{U}_i$}\RightLabel{\footnotesize ctx-EXT}
        \UnaryInfC{$(x_1{:}A_1, \dots,x_n{:}A_n$) \text{ctx}}  \DisplayProof\\[.8em]
        \AxiomC{$(x_1{:}A_1, \dots,x_n{:}A_n$) \text{ctx}}  \RightLabel{\footnotesize Vble}
        \UnaryInfC{$x_1{:}A_1, \dots,x_n{:}A_n \vdash x_i:A_i$}  \DisplayProof
    \end{center}
    donde la regla ctx-EXT tiene la condición adicional de que {\color{red} la variable} $x_n$ debe ser distinta a las demás variables $x_1, \dots,x_{n-1}$, y la regla Vble requiere que {\color{red}para todo} $1 \leq i \leq n$. {\color{red} la variable $x_i$ es un termino del tipo $A_i$}.

    La regla ctx-EMP tiene 0 hipótesis, por lo que siempre es posible aplicarla.
\end{rules}

Ahora detallamos el comportamiento de igualdades por definición.

\begin{rules}
    (Reglas básicas de igualdades por definición)
    \begin{center}
        \AxiomC{$\Gamma \vdash a:A$}
        \UnaryInfC{$\Gamma \vdash a\equiv a:A$} \DisplayProof \hspace{2em}
        \AxiomC{$\Gamma \vdash a \equiv b:A$}
        \UnaryInfC{$\Gamma \vdash b\equiv a:A$} \DisplayProof \hspace{2em}
        \AxiomC{$\Gamma \vdash a \equiv b:A$}
        \AxiomC{$\Gamma \vdash b \equiv c:A$}
        \BinaryInfC{$\Gamma \vdash a\equiv c:A$} \DisplayProof  \\[1.2em]
        \AxiomC{$\Gamma \vdash a :A$}
        \AxiomC{$\Gamma \vdash A \equiv B : \mathcal{U}_i$}
        \BinaryInfC{$\Gamma \vdash a:B$} \DisplayProof \hspace{1.5em}
        \AxiomC{$\Gamma \vdash a \equiv b :A$}
        \AxiomC{$\Gamma \vdash A \equiv B : \mathcal{U}_i$}
        \BinaryInfC{$\Gamma \vdash a \equiv b : B$} \DisplayProof
    \end{center}
\end{rules}

Las tres primeras reglas de $\equiv$ indican que esta es una relación de equivalencia, mientras las otras formalizan el buen comportamiento de juicios respecto a tipos iguales por definición.

En las siguientes secciones introduciremos reglas para la formación, introducción y eliminación de algunos constructos {\color{red} revisar el uso de palabra constructo}.
Para cada una de estas reglas, existe una regla correspondiente indicando que estas reglas preservan la igualdad por definición.
Como es com\'un es la presentaci\'on de reglas de DTT, estas ser\'an omitidas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de funciones}

 {\color{red} El desarollo de la Matem\'atica cl\'asica  en las diferentes areas de investigacion se debe en gran parte a la noci\'on de funciones, en esta secci\'on presentaremos la versi\'on an\'aloga a esta noci\'on en Teor\'ia de Tipos Dependientes} La noción de función es imprescindible en MC, presentamos ahora su análogo en DTT.

\begin{definition}
    Dados dos tipos $A$ y $B$, el tipo $A \to B$ es llamado el \textbf{tipo de funciones} de $A$ a $B$. Un elemento  $f:A \to B$ es llamado \textbf{función}. En este caso, decimos que $A$ es el \textbf{dominio} de $f$ y $B$ es el \textbf{codominio} de $f$.
\end{definition}

Intuitivamente, para construir una función $f:A \to B$, es suficiente que, dado $x:A$, podamos generar una expresión $b:B$ que est\'e bien definida, donde $b$ puede contener la variable $x$ dentro de ella.
Esto sugiere las siguientes reglas.

\begin{rules}
    (Reglas de formación de funciones)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \mathcal{U}_i$}
        \AxiomC{$\Gamma \vdash B : \mathcal{U}_i$} \RightLabel{\footnotesize $\to$-FORM}
        \BinaryInfC{$\Gamma \vdash A \to B : \mathcal{U}_i$} \DisplayProof  \hspace{1.8em}
        \AxiomC{$\Gamma, x:A \vdash b :B$}  \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma \vdash \lam{x:A}b : A \to B$}  \DisplayProof
    \end{center}
\end{rules}

La expresión $\lam{x:A}b$ puede {\color{red} interpretarse en Matem\'atica clasica como la regla de correspondencia de la funci\'on $f:A\to B$ definida por $b=f(x)$}
\sout{entenderse como una función $f$ definida por $f(x)=b$,} solo que se ha omitido el nombre $f$.
Por este motivo, a veces en la literatura estas funciones se llaman funciones anónimas.
En este documento nosotros las llamaremos funciones lambda, el nombre original que les dio Alonzo Church {\color{red} en [Nonmbre del articulo]}.

En la expresi\'on $\lam{x:A}b$, {\color{red} se dice} que $x$ es una \textbf{variable ligada} en $b$.
Esto es similar a c\'omo {\color{red} a las expresiones} $\forall x$ o $\int -  \, \text{dx}$  ligan la variable $x$ en una expresión.
Si una variable no es ligada, {\color{red} se dice} que es una \textbf{variable libre}.

Si $f$ es una función de $A$ e{\color{red}n} $B$, entonces podemos aplicarla a un elemento $a:A$ para conseguir un elemento de $b:B$. Intuitivamente, esto se da reemplazando todos las apariciones de $x$ por $a${\color{red}, como se podr\'a apreciar en las siguiente reglas.}

\begin{rules}
    (Reglas de aplicación de funciones)
    \begin{center}
        \AxiomC{$\Gamma \vdash f : A\to B$}
        \AxiomC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\to$-ELIM}
        \BinaryInfC{$\Gamma \vdash f(a) : B$} \DisplayProof  \\[.8em]
        \AxiomC{$\Gamma, x:A \vdash b: B$}
        \AxiomC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\to$-COMP}
        \BinaryInfC{$\Gamma \vdash (\lam{x:A}b)(a) \equiv b[a/x] : B$} \DisplayProof
    \end{center}
    donde la expresión $b[a/x]$ indica que reemplazaremos todas las apariciones libres de $x$ con $a$.
\end{rules}

{\color{red} Se observa que en Matem\'atica cl\'asica una funci\'on $f$ de $A$ en $B$ est\'a definido como un subconjunto del producto cartesiano  $A\times B$ el cual satisface  la siguiente condici\'on: Para todo $x\in A$ existe un \'unico $y\in B$ tal que $(x,y)\in f$, este ultimo hecho es descrito en la  segunda regla (COMP) en la versi\'on para Teor\'ia de Tipos Dependientes }


Para el ejemplo siguiente consideremos el tipo de los naturales $\N$ el cual ser\'a introducido posteriormente.


\begin{example}
    Formaremos la función identidad en tipo $\N$ y la aplicaremos en el elemento 0. {\color{red}El tipo $\N$ será introducido posteriormente (Eliminar)}. Sea $\Gamma$ igual a $\N{:}\,\UU$, entonces
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, n{:} \N$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, n{:}\N \vdash n:\N$}  \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma \vdash \lam{n:\N}n : \N \to \N$}  \DisplayProof
    \end{center}
    Esto muestra que la función existe y tiene el tipo adecuado. Sea $\Gamma$ igual a $\N{:}\,\mathcal{U}, 0{:}\,\N$, veremos que la función se comporta adecuadamente
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, n{:} \N$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, n{:}\N \vdash n: \N$}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma \vdash 0:\N$} \RightLabel{\footnotesize $\to$-COMP}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma \vdash (\lam{n:\N}n)(0) \equiv x[0/x] {\color{red} n[0/n]}: \N$}
        \UnaryInfC{$\Gamma \vdash (\lam{n:\N}n)(0) \equiv 0 : \N$} \DisplayProof
    \end{center}
\end{example}

\begin{definition}
    Sea $A$ un tipo, la función identidad $\idfunc[A]:A\to A$ está definida por $$\idfunc[A]\defeq \lam{x:A}x$$
\end{definition}

\begin{notation}
    Usaremos el símbolo $\defeq$ para dar definiciones. Una definición debe considerarse solo como una abreviación.
    El símbolo $\defeq$ no pertenece a DTT {\color{red} per se}, sino solo es un mecanismo para reducir la notación en la práctica matemática.
\end{notation}

Como mencionamos en la introducción, ya {\color{red} la funci\'on identidadel cual es simple} est\'a función simple representa una mejora respecto a MC. {\color{red} Al considerar} el tipo de todos los conjuntos $\mathsf{Set}$, la función $\idfunc[\mathsf{Set}]$ es la función identidad en todos los conjuntos, un concepto imposible de formalizar en MC.

\begin{notation}
    Omitiremos a veces el tipo de una expresión y su contexto asociado, cuando estos no sean relevantes o sean posibles de inferir fácilmente. De esta forma, escribiríamos el juicio derivado en el ejemplo previo como $\idfunc[\N] (0) \equiv 0$.
\end{notation}

Para introducir funciones de varias variables, podríamos introducir el tipo de productos $A \times B$ y definir $f: (A \times B)\to C$.
Una alternativa equivalente, pero m\'as conveniente, es {\color{red} introducir} el uso de funciones \lq\lq currificadas\rq\rq (\textit{curried functions}) {\color{red} estudiadas en [cita]}. La currificación de {\color{red} funci\'on} $f{:(A\times B)\to C}$ es {\color{red} la funci\'on} $f': A \to (B \to C)$, de tal forma que si $a:A$ y $b:B$, entonces $f'(a)(b):C$.

\begin{example}
    Formaremos una función $A\to(B\to A)$ que es constante en la primera variable {\color{red}constante en la primera variable normalmente significa que $f(x,y)=g(y)$, corregir}. Sea $\Gamma \defeq A{:}\,\mathcal{U},\, B{:}\,\mathcal{U}$, tenemos
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, x{:} A$ ctx} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, x{:}A, y{:}B$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, x{:}A, y{:}B \vdash x{:}A$}  \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma, x{:}A \vdash \lam{y:B}x : B \to A$} \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma \vdash \lam{x:A}(\lam{y:B}x) :A \to (B \to A)$}  \DisplayProof
    \end{center}
    Sea {\color{red} Si} $\Gamma \defeq A{:}\,\mathcal{U},\, B{:}\,\mathcal{U},\, a{:}\,A,\, b{:}\,B$, {\color{red}entonces } el buen comportamiento es mostrado por
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, x{:} A$ ctx} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, x{:}A, y{:}B$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, x{:}A, y{:}B \vdash a {\color{red}x}:A$}  \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma, x{:}A \vdash \lam{y:B}a{\color{red}x}: B \to A$}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\to$-COMP}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma \vdash \lam{x:A}(\lam{y:B}x)(a) \equiv (\lam{y:B}x)[a/x] : B \to A$}
        \UnaryInfC{$\Gamma \vdash \lam{x:A}(\lam{y:B}x)(a) \equiv \lam{y:B}a  : B \to A$} \DisplayProof
    \end{center}
    y
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, y{:}B$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, y{:}B \vdash a:A$}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma \vdash b:B$} \RightLabel{\footnotesize $\to$-COMP}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma \vdash (\lam{y:B}a)(b) \equiv a[b/y] : A$}
        \UnaryInfC{$\Gamma \vdash (\lam{y:B}a)(b) \equiv a :A$} \DisplayProof
    \end{center}
    Juntando estas dos derivaciones, obtenemos que
    $$\lam{x:A}(\lam{y:B}x)(a)(b) \equiv (\lam{y:B}a)(b) \equiv a$$
\end{example}

\begin{notation}
    Cuando puedan ser inferidas o no sean relevantes, omitiremos también el tipo de las variables dentro de una función lambda. Por ejemplo, escribiríamos $\lam{x:A}\lam{y:B}\Phi$ como $\lamu{x}\lamu{y}\Phi$.

    Si $f:A_1 \to \cdots \to (A_{n-1} \to A_n)$,  { \color{red}es una funci\'on entonces} escribiremos $f(x_1)(x_2)\cdots(x_n)$ como $f(x_1, x_2, \dots, x_n)$.
    Esto no traerá ambigüedad, puesto que el tipo de $f$ indicará si es una función currificada o una función cuyo dominio es un producto de tipos.
\end{notation}

Una operación común entre funciones es la composición, la siguiente derivación muestra que esta operación efectivamente existe.

\begin{example}
    Sea $\Gamma \defeq A{:}\mathcal{U}, B{:}\mathcal{U},  C{:}\mathcal{U}$, primero veremos que podemos expandir este contexto adecuadamente; es decir $\Gamma \vdash \Gamma, g{:}B\to C, f{:}A\to B, x{:}A \text{ ctx}$.
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma \vdash B : \mathcal{U}_i$ ctx}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma \vdash C : \mathcal{U}_i$ ctx} \RightLabel{\footnotesize $\to$-FORM}
        \def\defaultHypSeparation{\hskip 2.5em}
        \BinaryInfC{$\Gamma \vdash B\to C{:} \mathcal{U}_i$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, ({\color{red}g:B\to C}B\to C{:} \mathcal{U}_i)$ ctx}
        \DisplayProof
    \end{center}
    Adem\'as,
    \begin{center}
        \AxiomC{$\Gamma, (B\to C{:} \mathcal{U}_i)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i) \vdash A : \mathcal{U}_i$}
        \AxiomC{$\Gamma, (B\to C{:} \mathcal{U}_i)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i) \vdash B : \mathcal{U}_i$} \RightLabel{\footnotesize $\to$-FORM}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i) \vdash A\to B{:} \mathcal{U}_i$}\RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i), (A\to B{:} \mathcal{U}_i)$ ctx}\RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i), (A\to B{:} \mathcal{U}_i) \vdash {\color{red}???}g: B \to C$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i), (A\to B{:} \mathcal{U}_i), (g{:} B \to C)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i), (A\to B{:} \mathcal{U}_i), (g{:} B \to C) \vdash f: A \to B$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i), (A\to B{:} \mathcal{U}_i), (g{:} B \to C), (f{:} A \to B)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i), (A\to B{:} \mathcal{U}_i), (g{:} B \to C), (f{:} A \to B) \vdash x:A$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, (B\to C{:} \mathcal{U}_i), (A\to B{:} \mathcal{U}_i), (g{:} B \to C), (f{:} A \to B), (x:A)$ ctx}
        \DisplayProof
    \end{center}
    Poniendo $\Gamma' \defeq \Gamma, (B\to C{:} \mathcal{U}_i), (A\to B{:} \mathcal{U}_i)$, tenemos que
    \begin{center}
        \AxiomC{$\Gamma', (g{:}B\to C), (f{:}A\to B), (x{:}A)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma', (g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash f: A \to B$} \DisplayProof
    \end{center}
    \begin{center}
        \AxiomC{$\Gamma', (g{:}B\to C), (f{:}A\to B), (x{:}A)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma', (g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash x: A$}\DisplayProof
    \end{center}
    Juntando estas dos derivaciones
    \begin{center}
        \AxiomC{$\Gamma', \dots, x:A\vdash f: A \to B$}
        \AxiomC{$\Gamma', \dots, x{:}A\vdash x: A$} \RightLabel{\footnotesize $\to$-ELIM}
        \BinaryInfC{$\Gamma',(g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash f(x) : B$} \RightLabel{\footnotesize $\to$-ELIM} \DisplayProof
    \end{center}
    Similarmente tenemos que
    \begin{center}
        \AxiomC{$\Gamma', (g{:}B\to C), (f{:}A\to B), (x{:}A)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma', (g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash g: B \to C$} \DisplayProof
    \end{center}
    y finalmente llegamos a
    \begin{center}
        \AxiomC{$\Gamma',\dots, x{:}A \vdash g: B \to C$}
        \AxiomC{$\Gamma',\dots, x{:}A \vdash f(x) : B$} \RightLabel{\footnotesize $\to$-ELIM}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma', (g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash g(f(x)) : C$}   \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma', (g{:}B\to C), (f{:}A\to B) \vdash \lam{x:A}g(f(x)) : A \to C$}   \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma', (g{:}B\to C) \vdash \lamu{f}(\lam{x:A}g(f(x))) : (A \to B) \to (A \to C)$}  \RightLabel{\footnotesize $\to$-INTRO}
            \UnaryInfC{$\Gamma' \vdash \lamu{g}\lamu{f}(\lam{x:A}g(f(x))) : (B \to C) \to (A \to B) \to (A \to C)$}  \DisplayProof
    \end{center}
    Esto muestra que la función
    \begin{align*}
        \mathsf{comp}_{A,B,C} & : (B \to C) \to (A \to B) \to (A \to C)                 \\{\color{red}???}
        \mathsf{comp}_{A,B,C} & \defeq \lam{g:B\to C}\lam{f:A\to B}(\lam{x{:}A}g(f(x)))
    \end{align*}
    existe.  Omitiremos {\color{red} (Aplicando la regla COMP, obtenemos que la funci\'on $comp{A,B,C}$ se comporta como  se espera; ...)} la prueba de que se comporta como esperaríamos, es decir que $\mathsf{comp}_{A,B,C}(g,f,x)\equiv g(f(x))$. También omitiremos el hecho conocido de que la composición es asociativa, es decir
    \[ \mathsf{comp}_{A,C,D}(h, \mathsf{comp}_{A,B,C}(g,f)) \equiv \mathsf{comp}_{A,B,D}(\mathsf{comp}_{B,C,D}(h,g), f)\]
\end{example}

La \'ultima regla de funciones indica que si formamos una nueva función lambda, que recibe $x$ y devuelve $f(x)$ entonces esta es la misma función que la $f$ original.

\begin{rules}
    (Principio de unicidad para funciones)
    \begin{center}
        \AxiomC{$\Gamma \vdash f : A\to B$} \RightLabel{\footnotesize $\to$-UNIQ}
        \UnaryInfC{$\Gamma \vdash f \equiv (\lam{x :A}f(x)):A \to B$} \DisplayProof
    \end{center}
    {\color{red} En Matem\'atica cl\'asica se tiene que dos funciones $f,g\subset A\times B$ son iguales si y solomente $\Dom(f)=\Dom(g)...$Este principio nos dice que si se tiene  $f,g:A\to B$ tal que $\lam{x :A}f(x)\equiv \lam{x :A}g(x):A\to B$ entonces $f\equiv g:A\to B$ }
\end{rules}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de funciones dependientes}
En Matem\'atica Clasica, una pr\'actica com\'un es utilizar sucesiones infinitas de elementos $x_i$ de un conjunto $X$.
Formalmente, esto corresponde a una funci\'on $f : \N \to X$.
Similarmente, a veces es necesario indexar no solo elementos, sino conjuntos con cierta estructura por otros conjuntos.
Por ejemplo, a cada punto $p$ en una variedad $M$, le corresponde su espacio tangente $T_pM$.
Se entiende que esta \'ultima construcci\'on est\'a asociada a cierta funci\'on $g:M \to \bigcup_{p\in M}\{T_pM\}$.
En este \'ultimo caso, es com\'un decir que $\{T_pM\}_{p\in M}$ es una familia de conjuntos indexada por $p \in M$.
Presentamos el constructo an\'alogo en DTT.

\begin{definition}
    Si tenemos que $\Gamma, x:A \vdash B: \UU$, {\color{red}entonces} diremos que $B$ es una \textbf{familia de tipos} indexada por $x :A$.
\end{definition}

Recordamos que $B$ no es el car\'acter `$B$', sino una expresión arbitraria, por lo que esta puede contener la variable $x$ dentro de s\'i.
Adem\'as, notamos que el requerimiento que $\Gamma, x:A \vdash B: \UU$ es equivalente a que exista un $f: A \to \UU$, por lo que en este caso también diremos que $B$ es una familia de tipos.

\begin{example}
    Cada punto $x$ en un espacio topol\'ogico $X$ tiene asociado un grupo, su grupo fundamental.
    Es decir,  $\Gamma, x:X \vdash \pi_1(x,X) : \UU$.
\end{example}

\begin{example}
    Sea $B : \UU$ un tipo, para todo $a:A$, se tiene $\Gamma, a:A \vdash B : \UU$ .
    En este caso, decimos que $B$ es una \textbf{familia constante}.
\end{example}

N\'otese que en el caso de familias constantes, una función $f:A\to B$ asigna a cada $a:A$ un elemento $f(a): B$.
Esto se puede generalizar para familias arbitrarias.

\begin{example}
    Sea $X$ un espacio topol\'ogico, para cada $x:X$ podemos escoger un elemento de $\pi_1(x,X) : \UU$, el elemento neutro de ese grupo $0_{\pi_1(x,X)}$.
\end{example}

En este \'ultimo ejemplo tenemos una regla de correspondencia, por lo que se esperar\'ia que podemos formar una función $f$ con el tipo $X \to \pi_1(x,X)$.
Sin embargo, este tipo previo no est\'a bien tipado, el $x$ que aparece en el codominio no est\'a definido.
El problema es que el codominio depende del $x:X$ escogido en el dominio, para estos casos necesitaremos el tipo de \textbf{funciones dependientes} {\color{red} que ser\'a denotado por} $\tprd{x:A} B$.

\begin{rules}
    (Reglas de formación de funciones dependientes)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \mathcal{U}_i$}
        \AxiomC{$\Gamma, x:A \vdash B : \mathcal{U}_i$} \RightLabel{\footnotesize $\Pi$-FORM}
        \BinaryInfC{$\Gamma \vdash \tprd{x:A} B : \mathcal{U}_i$} \DisplayProof  \\[.8em]
        \AxiomC{$\Gamma, x:A \vdash b :B$}  \RightLabel{\footnotesize $\Pi$-INTRO}
        \UnaryInfC{$\Gamma \vdash \lam{x:A}b : \tprd{x:A} B$}  \DisplayProof
    \end{center}
    donde la expresi\'on $\tprd{x:A} B$ {\color{red} est\'a ligada a}
    liga a $x$ hasta el final de esta.
\end{rules}

Con estas reglas, se puede definir el tipo $\tprd{x:X}\pi_1(x,X)$, y una de las funciones pertenecientes a este tipo ser\'ia $\lam{x:X}0_{\pi_1(x,X)}$.

Igual que en el caso de funciones no dependientes, tenemos reglas que nos indican el proceso de aplicación de estas funciones, as\'i como un principio de unicidad.

\begin{rules}
    (Reglas de aplicación de funciones)
    \begin{center}
        \AxiomC{$\Gamma \vdash f : \tprd{x:A} B$}
        \AxiomC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\Pi$-ELIM}
        \BinaryInfC{$\Gamma \vdash f(a) : B[a/x]$} \DisplayProof  \\[.8em]
        \AxiomC{$\Gamma, x:A \vdash b: B$}
        \AxiomC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\Pi$-COMP}
        \BinaryInfC{$\Gamma \vdash (\lam{x:A}b)(a) \equiv b[a/x] : B[a/x]$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash f : \tprd{x:A} B$} \RightLabel{\footnotesize $\Pi$-UNIQ}
        \UnaryInfC{$\Gamma \vdash f \equiv (\lam{x :A}f(x)):\tprd{x:A} B$} \DisplayProof
    \end{center}
\end{rules}

Notamos que estas reglas son generalizaciones directas de las reglas de funciones introducidas en la sección anterior.
En efecto, tomaremos estas como las reglas oficiales y definiremos el tipo $A \to B$ como $\tprd{x:A}B$; { \color{red}  con (puesto que en este caso) $B$  una familia constante}, y se tiene que $B[a/x]$ es $B$, con lo que se obtienen las reglas originales.

\begin{notation}
    Los variables ligadas por $\Pi$ tienen menor precedencia que otros operadores dentro de un tipo, por lo que $\tprd{x:A}B \to C$ se entiende como $\tprd{x:A}(B \to C)$, por ejemplo.
    Adem\'as, para acentuar el \'enfasis de la (posible) dependencia de $B$ sobre $x$, escribiremos $\tprd{x:A} B(x)$, entendiendo por esto como simplemente $\tprd{x:A} B$.
    Finalmente, mencionamos que existe otra notación alternativa para $\tprd{x:A} B(x)$, como
    $$\prd{x:A} B(x) \hspace{1em} \text{ y } \hspace{1em} \Pi(x:A), B(x).$$
\end{notation}

El uso del s\'imbolo $\Pi$ sugiere que este tipo puede ser interpretado también como el producto cartesiano de lo $B_i$, como lo muestra el pr\'oximo ejemplo.
La siguiente {\color{red} ejemplo (discusi\'on)} es informal, utilizaremos algunos t\'erminos de teor\'ia de conjuntos para ayudar {\color{red} a una mejor escritura (la exposici\'on)}.
Sin embargo, estas nociones no est\'an definidas para DTT en este punto.

\begin{example}
    \label{piexample}
    Sea $A$ un tipo con tres elementos $a_1, a_2, a_3$ y sean $X, Y, Z$ tres tipos con $m,n$ y $p$ elementos respectivamente.
    Podemos asignar {\color{red} al elemento $a_1$ el tipo $X$ al elemento $a_2$ el tipo $Y$ y al elemento $a_3$ el tipo $Z$ (el tipo $X$ a $a_1$, $Y$ a $a_2$ y $Z$ a $a_3$)}, esto nos da una familia de tipos $B: A \to \UU$.\\
    Una función $f:\tprd{x:A}B$ asigna a cada $x:A$ un elemento de $B(x)$.
    \begin{center}
        \begin{tabular}{ c c c }
            $x:A$ &  & $B(x)$                                                    \\ \hline
            $a_1$ &  & $B(a_1)\equiv X \equiv \{x_1, \dots, x_m\}$               \\
            $a_2$ &  & $B(a_2)\equiv Y \equiv \{y_1, \dots, y_n\}$               \\
            $a_3$ &  & $B(a_3)\equiv Z \equiv \{z_1, \dots, z_{\color{red}o}p\}$
        \end{tabular}
    \end{center}
    {\color{red}Definamos la función $f_{i,j,k}:\tprd{x:A}B(x)$ por $f(a_1)=x_i,f(b_1)=y_j,f(a_3)=z_k$ donde $ 1\leq i\leq m,\,\,i\leq j\leq n,\,\, 1\leq k\leq p $.}
    De esta forma, los elementos de $\tprd{x:A}B(x)$ corresponden exactamente a triples $(x,y,z)$ con $x:X,\,y:Y$ y $z:Z$.
        {\color{red} Esto muestra}, el n\'umero de funciones en $\tprd{x:A}B(x)$, es el n\'umero de elecciones posibles para cada $a_i$, es decir
    $$ \left| \prd{x:A}B(x)\right| = \prod_{x:A}|B(x)| = |X|\cdot|Y|\cdot|Z|$$
    El hecho de que $|A \to B|=|B|^{|A|}$ es un caso particular de esto.
\end{example}

Una peque\~na limitaci\'on de la función $\idfunc[A]:A \to A$ es que est\'a definida solo para {\color{red} el tipo} $A$.
Formalmente, tendr\'iamos que crear una nueva función $\idfunc[T] $ para cada tipo $T$.
Las funciones dependientes evitan la repetici\'on de este proceso.

\begin{example}
    Existe una función $\mathsf{id}$ que asigna a cada $A: \UU$, su función identidad $\idfunc[A]: A \to A$.
    \begin{center}
        \AxiomC{$A:\UU$ ctx} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$A:\UU, x:A$ ctx}\RightLabel{\footnotesize Vble}
        \UnaryInfC{$A:\UU, x:A \vdash x:A$}\RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$A:\UU \vdash \lam{x:A}x : A\to A$}\RightLabel{\footnotesize $\Pi$-INTRO}
        \UnaryInfC{$\cdot \vdash \lam{A:\UU}\lam{x:A}x: \prd{A:\UU}A \to A$} \DisplayProof
    \end{center}
    {\color{red} El buen comportamiento esta dado por:(escribir la regla de comp)} Omitimos la derivación de su buen comportamiento.
\end{example}

{\color{red} En los (Dados estos tres)} \'ultimos ejemplos, vemos que dada una función lambda bien tipada, es un proceso simple (pero tedioso) generar la derivación de su existencia y buen comportamiento.
Por este motivo, en las secciones siguientes comenzaremos a escribir solamente la función lambda y omitiremos las derivaciones asociadas.

\begin{notation}
    Es común en Matem\'atica Cl\'asica definir funciones a partir de reglas de correspondencia; es decir, definiendo $f$ por su comportamiento en un $x$ arbitrario.
    Utilizaremos esta misma pr\'actica, entendiendo estas definiciones como una abreviación de funciones lambda.
    Por ejemplo, la definici\'on de la función
    \begin{gather*}
        \idfunc  :\prd{A:\UU}A\to A \\
        \idfunc  \defeq \lam{A:\UU}\lam{x:A}x
    \end{gather*}
    Puede ser reescrita simplemente como
    \begin{gather*}
        \idfunc         :\prd{A:\UU}A\to A \\
        \idfunc  (A,x)  \defeq x
    \end{gather*}
    Finalmente, para funciones currificadas de varios par\'ametros, se asociaran aplicaciones repetidas de `$\to$' por la derecha, por lo que $A \to B \to C$ se entiende como $A \to (B \to C)$, por ejemplo.
    Todos los dem\'as constructos por introducir asociar\'an hacia la izquierda, de tal forma que $A \times B \times C$ es $(A \times B) \times C$.
\end{notation}

\begin{example}
    Existe una función $\mathsf{swap}$ que invierte el orden de las variables de una función de dos parámetros.
    \[ \mathsf{swap}: \prd{A:\UU}\prd{B:\UU}\prd{C:\UU} (A \to B \to C) \to (B \to A \to C)\]
    Y esta est\'a definida por
    \[ \mathsf{swap}(A,B,C{\color{red},f}) \defeq \lam{b:B}\lam{a:A} f(a,b) \]
    Notamos que de acuerdo a la notación anterior, esta también pudo haber sido definido como:
    \[ \mathsf{swap}(A,B,C,f,b,a)\defeq f(a,b) \]
\end{example}

Como se esperaría, podemos definir una nueva noción de composición de funciones, en donde la segunda de las funciones por componer es una función dependiente.
\begin{definition}
    Dados dos tipos $A, B$ y una familia de tipos $C : B \to \UU$, podemos definir la funci\'on de composici\'on de funciones
    \[ \mathsf{comp}^*_{A,B,C} \defeq {\color{red}\left(\prd{y:B}C(y) \right) } \to \prd{f:A\to B} \prd{x:X} C(f (x )) \]
    dada por
    \[ \mathsf{comp}^*_{A,B,C}(g,f,x) \defeq g (f (x)) \]

    Como es usual, escribiremos $g \circ f$ en vez de $\mathsf{comp}^*_{A,B,C}(g,f,x)$ {\color{red}eliminar x}, dejando los índices implícitos.
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{El tipo de pares dependientes}
 {\color{red} Falta tipos productos}
As\'i como el tipo de funciones $A \to B$ es un caso particular del tipo de funciones dependientes $\tprd{x:A} B(x)$ el tipo de pares $A \times B$ es un caso particular del tipo de pares dependientes $\tsm{x:A}B$ donde $B$ puede depender de $x:A$.

Intuitivamente, dados dos elementos $a:A$ y $b:B(a)$ es posible generar el par $(a,b)$. Las siguientes reglas formalizan esto\footnote{El uso del tipo de funciones en estas reglas podr\'ia hacer parecer que estas tienen un rol m\'as fundamental que el de pares dependientes; sin embargo, es posible formalizar estas reglas sin hacer menci\'on a las funciones, ver \cite[Ap\'endice A.2.]{the_univalent_foundations_program_homotopy_2013} }.

\begin{rules}
    (Reglas de formación de pares dependientes)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \mathcal{U}_i$}
        \AxiomC{$\Gamma \vdash B : A \to \mathcal{U}_i$} \RightLabel{\footnotesize $\Sigma$-FORM}
        \BinaryInfC{$\Gamma \vdash \tsm{x:A} B : \mathcal{U}_i$} \DisplayProof  \\[.8em]
        \AxiomC{$\Gamma \vdash B : A \to \mathcal{U}_i$}
        \AxiomC{$\Gamma \vdash a:A$}
        \AxiomC{$\Gamma \vdash b:B(a)$}  \RightLabel{\footnotesize $\Sigma$-INTRO}
        \TrinaryInfC{$\Gamma \vdash (a,b) : \tsm{x:A} B$}  \DisplayProof
    \end{center}
    donde la expresi\'on $\tsm{x:A} B$ liga a $x$ hasta el final de esta.
\end{rules}

\begin{notation}
    En caso $B$ sea una familia constante, escribiremos también $A \times B$ en vez de $\tsm{x:A} B$.
    Los variables ligadas por $\Sigma$ tienen menor precedencia que otros operadores dentro de un tipo, por lo que $\tsm{x:A}B \to C$ se entiende como $\tsm{x:A}(B \to C)$, por ejemplo.

    En el caso del producto `$\times$', este tiene mayor precedencia que `$\to$', por lo que $A\times B \to C$ se interpreta como $(A\times B) \to C$. Lo mismo aplica para el coproducto `$+$' definido en la pr\'oxima sección.

    Adem\'as, para acentuar el \'enfasis de la (posible) dependencia de $B$ sobre $x$, escribiremos $\tsm{x:A} B(x)$, entendiendo por esto como simplemente $\tsm{x:A} B$.
    Finalmente, mencionamos que existe otra notación alternativa para $\tsm{x:A} B(x)$, como
    $$\sm{x:A} B(x) \hspace{1em} \text{ y } \hspace{1em} \Sigma(x:A), B(x).$$
\end{notation}

Similarmente al caso de funciones dependientes, el uso del símbolo $\Sigma$ sugiere que este tipo puede ser interpretado también como una suma (disjunta) de los $B_i$, como lo muestra el próximo ejemplo informal.

\begin{example}
    Sea $A = \{a_1, a_2, a_3\}$ y sean $X, Y, Z, B$ como en el Ejemplo \ref{piexample}.
    El tipo de pares dependientes $\tsm{x:A}B$ contiene pares $(a,b)$ con $a:A$ y $b:B(a)$.
    Por ejemplo, podemos definir un par $(a_1, x_1{\color{red} i}):\tsm{x:A}B$.
    De esta forma, los elementos de $\tsm{x:A}B$ corresponden exactamente a elementos de la unión disjunta de los elementos de $X,Y$ y $Z$.
    En efecto, tenemos
    $$ \left| \tsm{x:A}B\right| = \Sigma_{x:A}|B(x)| = |X| + |Y| + |Z|$$
\end{example}

Las reglas previas solo muestran c\'omo formar pares, para que estos sean \'utiles es necesario ver c\'omo se pueden usar; es decir, c\'omo formar funciones cuyo dominio sea un tipo de pares dependientes.
\begin{rules}
    (Reglas de eliminación de pares dependientes.)
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: (\tsm{x:A} B) \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash g : \tprd{a:A} \tprd{b:B(a)} C((a,b))$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash p : \tsm{x:A}B$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\Sigma$-ELIM}}
        \TrinaryInfC{$\Gamma \vdash \ind{\tsm{x:A} B} (C,g,p): C(p)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: (\tsm{x:A} B) \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash g : \tprd{a:A} \tprd{b:B(a)} C(a,b)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash a:A \hspace{2em} \Gamma \vdash b : B[a/x]$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\Sigma$-COMP}}
        \TrinaryInfC{$\Gamma \vdash \ind{\tsm{x:A} B} (C,g,((a,b)))\jdeq g(a)(b) : C((a,b))$}
        \DisplayProof
    \end{center}
\end{rules}

{\color{red}Describir que es ind}

Las reglas $\Sigma$-COMP y $\Sigma$-ELIM, nos dan el siguiente principio de inducción para pares dependientes.

\begin{theorem}
    Sea $A$ un tipo, $B:A \to \UU$ una familia de tipos sobre $A$, entonces existe una función
    \[
        \ind{\sm{x:A}B(x)} :
        \dprd{C:(\sm{x:A} B(x)) \to \UU}
        \Parens{\tprd{a:A}{b:B(a)} C(\tup{a}{b})}
        \to \dprd{p : \sm{x:A}B(x)} C(p)
    \]
    tal que
    $$\ind{\tsm{x:A} B{\color{red}(x)}} (C,g,(a,b))\jdeq g(a)(b) : C((a,b))$$
\end{theorem}

\begin{proof}
    Inmediato de las reglas.
\end{proof}

El principio de inducción para pares dependientes captura la adjunci\'on Hom:
$$ \text{Hom}(A \times B, C) \cong \text{Hom}(A,\text{Hom}(B,C))$$
En efecto, es esta equivalencia la que aprovechamos para nuestra definición de funciones currificadas.

Veamos como podemos utilizar este principio para mostrar la existencia de las funciones de proyección en cada uno de las coordenadas.

\begin{theorem}
    Sea $A$ un tipo y $B$ una familia de tipos sobre $A$. Entonces existen funciones $\fst$ y $\snd$ tales que $\fst(a,b)=a$ y $\snd(a,b)=b$.
\end{theorem}

\begin{proof}
    Sean
    \begin{gather*}
        C\defeq \lam{p}A : \sm{x:A}B(x) \to \UU \\
        g \defeq \lam{x}\lam{y}x : \prd{a:A} \prd{b:B(a)}A
    \end{gather*}
    Notando que $C({a,b}) \equiv A$, y aplicando el principio de inducción obtenemos
    \begin{gather*}
        \fst \defeq \ind{\Sigma}(C,g): \prd{p: \sm{x:A} B(x)}A\\
        \fst(a,b)\defeq \ind{\Sigma}(C,g,(a,b)) \equiv g(a)(b) \equiv a
    \end{gather*}
    De manera similar, tomando
    \begin{gather*}
        C' \defeq \lam{p} B(\fst(p)) : \sm{x:A} B(x) \to \UU \\
        g \defeq \lam{x}\lam{y}y : \prd{a:A} \prd{b:B(a)}B(a)
    \end{gather*}
    y notando que $C({a,b}) \equiv B(\fst((a,b)))\equiv B(a)$, aplicando el principio de inducción obtenemos
    \begin{gather*}
        \snd \defeq \ind{\Sigma}(C',g'): \prd{p: \sm{x:A} B(x)}B(\fst(p))\\
        \snd \defeq \ind{\Sigma}(C',g',(a,b)) \equiv g'(a,b) \equiv b
    \end{gather*}
    Por lo que ambas proyecciones existen.
\end{proof}

Aplicar directamente el principio de inducción requiere cierto nivel de cuidado, en MC cl\'asica definir\'iamos la función $\snd$ simplemente como $\snd((a,b))\defeq b$.
Veremos que esta pr\'actica también se puede realizar en DTT.

\begin{notation}
    (B\'usqueda de patrones para pares dependientes)\\
    Sea $A$ un tipo, $B:A \to \UU$ una familia de tipos sobre $A$ y $C: (\tsm{x:A}B(x)) \to \UU$.
    Podemos definir una función $f : \tprd{p:\tsm{x:A} B(x)}C(p)$ por
    $$f((a,b)) \defeq \Phi$$
    donde $\Phi : C((a,b))$ es una expresión que puede contener $a$ o $b$.
\end{notation}

\begin{justification}
    Dados $a:A$, $b:B(a)$ y $\Phi: C((a,b))$, podemos definir
    $$g\defeq \lam{a:A}\lam{b:B(a)}\Phi : \prd{a:A} \prd{b:B(a)}C((a,b))$$
    Entonces,
    $$f \defeq \ind{\Sigma}(C,g): \prd{p: \sm{x:A} B(x)}C(p)$$
    es tal que $f((a,b))\jdeq \Phi$.
\end{justification}

Esto justifica el hecho ``obvio'' de que basta definir una función en un par arbitrario para que la función est\'e bien definida en todo el tipo de pares dependientes.

\begin{notation}
    Omitiremos a veces los paréntesis de un par cuando estos est\'en dentro de una aplicación de una función o dentro de otro para. Por ejemplo, escribiremos $C(a,b)$ en vez de $C((a,b))$, y $(a, b,c)$ en vez de $(a, (b,c))$.
\end{notation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\emptyt, \unit, \bool y el tipo del coproducto}
El tipo $\emptyt:\UU$ representa el tipo vac\'io, por lo que si obtuvi\'esemos un elemento de \'el, esto ser\'ia un absurdo, y podr\'iamos concluir cualquier cosa. Las siguientes reglas capturan esta intuici\'on.

\begin{rules}
    (Reglas del tipo \emptyt.)
    \begin{center}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\emptyt$-FORM}
        \UnaryInfC{$\Gamma \vdash \emptyt : \UU_i$} \DisplayProof \hspace{.8em}
        \AxiomC{$\Gamma \vdash C : \emptyt \to \UU_i$}
        \AxiomC{$\Gamma \vdash z : \emptyt$} \RightLabel{\footnotesize $\emptyt$-ELIM}
        \BinaryInfC{$\Gamma \vdash \ind{\emptyt}(C,z) : C(z)$}  \DisplayProof
    \end{center}
\end{rules}

El principio de inducción del $\emptyt$ implica que dado un $z:\emptyt$ podemos generar un elemento de un tipo que (posiblemente) depende de $z$.

\begin{theorem}
    Existe una función
    \[ \ind{\emptyt} : \prd{C:\emptyt \to \UU}{z:\emptyt} C(z) \]
\end{theorem}

\begin{proof}
    Inmediato de las reglas.
\end{proof}

N\'otese que, en particular, el principio de inducci\'on del tipo $\emptyt$ nos da una funci\'on $\rec{\emptyt}(C):\emptyt \to C$, para todo tipo $C$. En efecto, podemos definir
\[ \rec{\emptyt}(C)(x) \defeq \ind{\emptyt} (\lamu{x} C,x) \]
Esto nos da indicios de que el tipo $\emptyt$ es un objeto inicial de la categor\'ia $\Type$, y este es efectivamente el caso; pero la demostraci\'on de la unicidad de la funci\'on $\rec{\emptyt}(C)$ tendr\'a que esperar (ver Proposici\'on \ref{0-initial}).

De manera an\'aloga, el tipo $\unit:\UU$ representa el tipo con un solo elemento $\ttt$, por lo que para generar una función con dominio es suficiente definirla en $\ttt$.
Las siguientes reglas dicen precisamente esto.

\begin{rules}
    (Reglas del tipo \unit.)
    \begin{center}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\unit$-FORM}
        \UnaryInfC{$\Gamma \vdash \unit : \UU_i$} \DisplayProof \hspace{.8em}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\unit$-INTRO}
        \UnaryInfC{$\Gamma \vdash \ttt : \unit$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash C : \unit \to \UU_i$}
        \AxiomC{$\Gamma \vdash c : C(\ttt)$}
        \AxiomC{$\Gamma \vdash a : \unit$} \RightLabel{\footnotesize $\unit$-ELIM}
        \TrinaryInfC{$\Gamma \vdash \ind{\unit}(C,c,a) : C(a)$}  \DisplayProof\\[.8em]
        \AxiomC{$\Gamma \vdash C : \unit \to \UU_i$}
        \AxiomC{$\Gamma \vdash c : C(\ttt)$}\RightLabel{\footnotesize $\unit$-COMP}
        \BinaryInfC{$\Gamma \vdash \ind{\unit}(C,c,\ttt) \jdeq c : C(\ttt)$}  \DisplayProof
    \end{center}
\end{rules}

El principio de inducción para $\unit$ es el siguiente.

\begin{theorem}
    Existe una función
    \[ \ind{\unit} : \prd{C:\unit \to \UU} C(\ttt) \to \prd{x:\unit}C(x)\]
    tal que
    \[ \ind{\unit}(C,c,\ttt) \defeq c. \]
\end{theorem}

\begin{proof}
    Inmediato de las reglas.
\end{proof}
El principio de inducción del $\unit$ nos permite usar la siguiente notación.

\begin{notation}
    (B\'usqueda de patrones para \unit)\\
    Sea $C:\unit \to \UU$ una familia de tipos sobre $\unit$.
    Podemos definir una función $f : \tprd{x:\unit}C(x)$ por
    $$f(\ttt) \defeq \Phi$$
    donde $\Phi : C(\ttt)$.
\end{notation}

\begin{justification}
    Dado $\Phi: C(\ttt)$, podemos definir
    $$f \defeq \ind{\unit}(C,\Phi): \prd{x: \unit}C(x)$$
    y este cumple que $f(\ttt)\jdeq \Phi$.
\end{justification}

Categ\'oricamente, el tipo $\unit$ es un objeto terminal de $\Type$, pues dado un tipo $C$ arbitrario, podemos definir una funci\'on $!\unit_{C}: C \to \unit$ por
\[ !\unit_{C} \defeq \lam{x:\unit}\star \]
Verificaremos que esta funci\'on es \'unica en la Proposici\'on \ref{1-terminal}.

Podr\'iamos ahora esperar poder definir $\bool$, el tipo con dos elementos, como la uni\'on disjunta de $\unit$ consigo mismo, a través de una un producto $\bool \defeq X \times \unit$, donde $X$ tiene dos elementos.
Esto es posible, pero no tenemos ning\'un $X$ que satisfaga esta propiedad.

Una alternativa es usando la noción del coproducto.
Dados dos tipos $A$ y $B$, su coproducto es denotado por $A+B$. Este puede ser entendido como una uni\'on disjunta de los dos tipos.

\begin{rules}
    (Reglas de formación del coproducto.)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \UU_i$ }
        \AxiomC{$\Gamma \vdash B : \UU_i$ } \RightLabel{\footnotesize $+$-FORM}
        \BinaryInfC{$\Gamma \vdash A+B : \UU_i$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash A : \UU_i$ }
        \AxiomC{$\Gamma \vdash B : \UU_i$ }
        \AxiomC{$\Gamma \vdash a : A$ } \RightLabel{\footnotesize $+$-INTRO$_1$}
        \TrinaryInfC{$\Gamma \vdash \inl (a) : A+B$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash A : \UU_i$ }
        \AxiomC{$\Gamma \vdash B : \UU_i$ }
        \AxiomC{$\Gamma \vdash b: B$ } \RightLabel{\footnotesize $+$-INTRO$_2$}
        \TrinaryInfC{$\Gamma \vdash \inr (b) : A+B$} \DisplayProof
    \end{center}
\end{rules}

De esta forma, \inl y \inr act\'uan como las inyecciones naturales hacia un coproducto.
As\'i, podemos definir $\bool \defeq \unit + \unit$, y este posee dos elementos $\inl(\ttt)$ e $\inr(\ttt)$.
Sin embargo, para poder utilizar un coproducto, debemos saber c\'omo definir funciones cuyo dominio sean estos.

\begin{rules} \label{coprodelim}
    (Reglas de eliminación del coproducto.)
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma  \vdash  C :A+B \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{x:A}C(\inl(x))$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash d: \tprd{y:B}C(\inl(y)) \hspace{2em} \Gamma \vdash e : A+B$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$+$-ELIM}}
        \TrinaryInfC{$\Gamma \vdash \ind{A+B}(C,c,d,e) : C(e)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma  \vdash  C :A+B \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{x:A}C(\inl(x))$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash d: \tprd{y:B}C(\inl(y)) \hspace{2em} \Gamma \vdash a : A$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$+$-COMP$_1$}}
        \TrinaryInfC{$\Gamma \vdash \ind{A+B}(C,c,d,\inl(a)) \jdeq c(a) : C(\inl(a))$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma  \vdash  C :A+B \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{x:A}C(\inl(x))$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash d: \tprd{y:B}C(\inl(y)) \hspace{2em} \Gamma \vdash b : B$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$+$-COMP$_2$}}
        \TrinaryInfC{$\Gamma \vdash \ind{A+B}(C,c,d,\inr(b)) \jdeq d(b): C(\inr(b))$}
        \DisplayProof
    \end{center}
\end{rules}

Estas reglas justifican el hecho de que basta definir una función en $A$ y en $B$ para que est\'e definida en $A+B$.
Esto es el principio de inducción para el coproducto.

\begin{theorem}
    Sean $A$ y $B$ tipos. Entonces existe una función
    \[
        \ind{A+B} :
        \dprd{C: (A + B) \to \UU}
        \Parens{\tprd{x:A} C(\inl(x))} \to
        \Parens{\tprd{y:B} C(\inr(y))} \to \tprd{e:A+B}C(e)
    \]
    tal que
    \begin{gather*}
        \ind{A+ B} (C,c,d,\inl(a)) \jdeq c(a) : C(\inl(a)) \\
        \ind{A+ B} (C,c,d,\inr(b)) \jdeq d(b) : C(\inl(b))
    \end{gather*}
\end{theorem}

\begin{proof}
    Inmediato de las reglas.
\end{proof}

Como en los tipos previos, podemos simplificar considerablemente la notación realizando una b\'usqueda de patrones.

\begin{notation}
    (B\'usqueda de patrones para el coproducto)\\
    Sean $A, B$ tipos, y $C:A+B \to \UU$ una familia de tipos sobre $A+B$.
    Podemos definir una función $f:\tprd{e:A+B}C(e)$ por
    \begin{gather*}
        f(\inl(a)) \defeq \Phi_{0} \\
        f(\inr(b)) \defeq \Phi_{1}
    \end{gather*}
    donde $\Phi_0 : C(\inl(a))$ y $\Phi_1 : C(\inr(b))$ son expresiones que pueden tener a `$a$' o a `$b$' respectivamente.
\end{notation}

\begin{justification}
    Dados $\Phi_0 : C(\inl(a))$ y $\Phi_1 : C(\inr(b))$, podemos definir
    $$f \defeq \ind{A+B}(C, \lam{a:A}\Phi_0,\lam{b:B}\Phi_1): \prd{e: A+B}C(e)$$
    y esta satisface $f(\inl(a)) \defeq \Phi_{0}$ y $f(\inr(b)) \defeq \Phi_{1}$.
\end{justification}

Analizaremos con m\'as detalle el tipo $\bool \defeq \unit + \unit$.
Escribiendo $\bfalse \defeq \inl(\ttt)$ y $\btrue \defeq \inr(\ttt)$, y por el principio de inducción para el coproducto, vemos que para definir una función $\tprd{x:\bool}C(x)$ es suficiente definir dos funciones $f : \unit \to C(\bfalse)$ y $g : \unit \to C(\btrue)$.
Pero por el principio de inducción de $\unit$, esto es lo mismo que seleccionar dos elementos, uno de $C(\bfalse)$ y otro de $C(\btrue)$.
De esta forma, obtenemos el principio de inducción para $\bool$.

\begin{theorem}
    Sea $C:\bool \to \UU$ una familia de tipos sobre $\bool$. Entonces existe una función
    \[
        \ind{\bool} :
        \dprd{C: \bool \to \UU}
        C(\bfalse) \to
        C(\btrue) \to
        \tprd{x:\bool}C(x)
    \]
    tal que
    \begin{gather*}
        \ind{\bool} (C,c_0,c_1,\bfalse) \jdeq c_0 : C(\bfalse) \\
        \ind{\bool} (C,c_0,c_1,\btrue) \jdeq c_1 : C(\btrue)
    \end{gather*}
\end{theorem}

Sea $C: \bool \to \UU$ definido por $C(\bfalse)\defeq A$ y $C(\btrue)\defeq B$, es intuitivo que $\tsm{x:2}C(x)$ sea equivalente, en cierto sentido, a $A +B$.
Este es efectivamente el caso (ver Cap\'itulo 2), y pudimos tambi\'en haber introducido primero el tipo $\bool$ y definir $A+B$ a partir de este.
Cu\'al es introducido primero no causa ninguna diferencia en los resultados.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de los naturales}
Aquellos tipos con un principio de inducci\'on son llamadas tipos inductivos.
Entre estos, el tipo de los naturales es el tipo inductivo por excelencia.
Intuitivamente, este consiste del conjunto $\{0,1,2,\dots\}$, pero n\'otese que a excepción del $0$ todo elemento $m$ puede ser escrito como $n+1$ para algún $n$.
Esto sugiere las siguientes reglas.

\begin{rules}
    (Reglas de formación de \N.)
    \begin{center}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\N$-FORM}
        \UnaryInfC{$\Gamma \vdash \N : \UU_i$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\N$-INTRO$_1$}
        \UnaryInfC{$\Gamma \vdash 0 : \N$} \DisplayProof \hspace{.8em}
        \AxiomC{$\Gamma \vdash n : \N$ } \RightLabel{\footnotesize $\N$-INTRO$_2$}
        \UnaryInfC{$\Gamma \vdash \suc (n) : \N$} \DisplayProof \hspace{.8em}
    \end{center}
\end{rules}

Ahora, el principio de inducción de los naturales es el usual.

\begin{rules}
    (Reglas de eliminación de \N.)
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: \N \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash c_0 : C(0)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash c_s: \tprd{n:\N}C(n) \to C(\suc(n)) \hspace{2em} \Gamma \vdash n:\N$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\N$-ELIM}}
        \TrinaryInfC{$\Gamma \vdash \ind{\N} (C,c_0,c_s,n) : C(n)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: \N \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash c_0 : C(0)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash c_s: \tprd{n:\N}C(n) \to C(\suc(n))$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\N$-COMP$_1$}}
        \TrinaryInfC{$\Gamma \vdash \ind{\N} (C,c_0,c_s,0) \jdeq c_0 : C(n)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: \N \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash c_0 : C(0)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash c_s: \tprd{n:\N}C(n) \to C(\suc(n)) \hspace{2em} \Gamma \vdash n:\N$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\N$-COMP$_2$}}
        \TrinaryInfC{$\Gamma \vdash \ind{\N} (C,c_0,c_s,\suc(n)) \jdeq c_s(n,\ind{\N} (C,c_0,c_s,n)) : C(\suc(n))$}
        \DisplayProof
    \end{center}
\end{rules}


\begin{theorem}
    Existe una función
    \[\ind{\nat}  : \dprd{C:\nat\to \UU} C(0) \to \Parens{\tprd{n : \nat} C(n) \to C(\suc(n))} \to \tprd{n : \nat} C(n) \]
    tal que
    \begin{align*}
        \ind{\nat}(C,c_0,c_s,0)       & \defeq c_0,                            \\
        \ind{\nat}(C,c_0,c_s,\suc(n)) & \defeq c_s(n,\ind{\nat}(C,c_0,c_s,n)).
    \end{align*}
\end{theorem}

\begin{proof}
    Inmediato de las reglas.
\end{proof}

\begin{notation}
    Podemos definir una función con dominio $\N$ a una familia de tipos $C:\N \to \UU$ definiendo su comportamiento en $0$ y $\suc(n)$, es decir
    \begin{gather*}
        f(0) \defeq \Phi_{0} : C(0) \\
        f(\suc(n)) \defeq \Phi_{1} : C(\suc(n))
    \end{gather*}
    donde $n$ y $f(n)$ pueden aparecer en $\Phi_{1}$.
\end{notation}

\begin{justification}
    $f$ puede ser definida como
    \[ f\defeq ind_{\N} (C,\Phi_{0},\lam{n}\lam{r}\Phi_{1}^*)\]
    donde $\Phi_{1}^*$, es $\Phi$ con todas las ocurrencias de $f(n)$ reemplazadas por $r$.
\end{justification}

Definimos los símbolos usuales para los números naturales como aplicaciones repetidas del constructo $\suc$. Es decir $1\defeq \suc(0), 2\defeq \suc(1), 3\defeq \suc(2), \dots$.

En el caso en el que la familia $C: \N \to \UU$ es constante, el principio de inducción se convierte en el principio de recursi\'on.
En efecto, para todos los tipos existe un principio de recursi\'on, el cual es simplemente el principio de inducci\'on aplicado a una familia constante.
Veamos dos ejemplos de esto:

\begin{example}
    Existe una función $\mathsf{double} : \N \to \N$ tal que duplica el valor su input.
    \begin{align*}
        \mathsf{double}           & :\N \to \N                            \\
        \mathsf{double} (0)       & \defeq 0                              \\
        \mathsf{double} (\suc(n)) & \defeq \suc(\suc(\mathsf{double}(n)))
    \end{align*}
    Por ejemplo,
    \begin{align*}
        \mathsf{double}(2) & \jdeq\mathsf{double}(\suc (\suc (0)))                   \\
                           & \jdeq \suc(\suc(\mathsf{double}(\suc (0))))             \\
                           & \jdeq \suc(\suc(\suc(\suc(\mathsf{double}(\suc (0)))))) \\
                           & \jdeq \suc(\suc(\suc(\suc(\mathsf{double}(0)))))        \\
                           & \jdeq 4
    \end{align*}

\end{example}

La función suma también es definida por recursi\'on
\begin{example}
    \begin{align*}
        \mathsf{add}          & :\N \to \N \to \N                       \\
        \mathsf{add}(0)       & \defeq \idfunc[\N]                      \\
        \mathsf{add}(\suc(n)) & \defeq \lam{m}\suc (\mathsf{add}(n)(m))
    \end{align*}
    A forma de recordatorio que la notación previa es solo una simplificaci\'on, mostramos la definición usando solo el principio de inducción:
    \[ \mathsf{add}\defeq \ind{\N} (\lam{n}(\N \to \N), \idfunc[\N], \lam{n}\lam{g}\lam{m}\suc(g(m))) \]
    Como es com\'un, utilizaremos $a+b$ para referirnos a $\mathsf{add}(a)(b)$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec10
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposiciones como tipos}
En la introducción habíamos mencionado que las proposiciones eran representadas como tipos en DTT.
Comenzaremos analizando cada uno de los constructos lógicos principales en MC.

\begin{itemize}
    \item Para mostrar que se cumple $P \wedge Q$, es suficiente mostrar que se cumplen ambos $P$ y $Q$.
          Podemos entonces considerar una prueba de $P \wedge Q$ como un par de pruebas de $P$ y $Q$.
    \item Para mostrar que se cumple $P \vee Q$, es suficiente mostrar que se cumple alguno de $P$ o $Q$.
          Podemos entonces considerar una prueba de $P \vee Q$ como la unión disjunta de pruebas de $P$ y $Q$.
    \item Para mostrar que se cumple $P \implies Q$, es suficiente mostrar que dado $P$, se puede mostrar que se cumple $Q$.
          Podemos entonces considerar una prueba de $P \implies Q$ como una función que toma una prueba de $P$ y devuelve una prueba de $Q$.
    \item Para mostrar que se cumple $\lnot P$, es suficiente mostrar que si es que tenemos $P$, podemos llegar a una contradicción.
          Podemos entonces considerar una prueba de $\lnot P$ como una función que toma una prueba de $P$ y devuelve una prueba de una contradicción.
    \item Para mostrar que se cumple $\forall x\in A, P(x)$, es suficiente mostrar que, dado un $x$ arbitrario en $A$, se puede mostrar que este satisface $P(x)$.
          Podemos entonces considerar una prueba de $\forall x\in A, P(x)$ como una función que toma cualquier elemento $x \in A$ y devuelve una prueba de $P(x)$.
    \item Para mostrar que se cumple $\exists x \in A, P(x)$, es suficiente mostrar que existe un $a \in A$ tal que $P(a)$.
          Podemos entonces considerar una prueba de $\exists x \in A, P(x)$ como un par, el cual consiste de un elemento $a \in A$ y una prueba de $P(a)$.
\end{itemize}

La interpretaci\'on de estos constructos de esta manera es llamada la \textbf{interpretaci\'on BHK},
debido a los nombres de sus principales proponentes L.\ E.\ J.\ Brouwer, Arend Heyting, y Andrey Kolmogorov.
Notemos su similitud con las reglas de introducción para los tipos que ya hemos introducido.

Por ejemplo, la regla de introducción para el tipo del producto indica que para construir un elemento de $P \times Q$ es suficiente mostrar dos elementos $a:P$ y $b:Q$, y el nuevo elemento construido ser\'ia el par $(a,b)$ de estos.
As\'i, los tipos se interpretan como proposiciones y los elementos de estos tipos se interpretan como pruebas o evidencia de estas proposiciones.
Esta correspondencia entre l\'ogica y tipos es llamada el \textbf{isomorfismo de Curry-Howard}.

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ l l }
            \thickhline
            Matemática Clásica      & Teoría de Tipos dependientes \\
            \hline
            $A \wedge B$            & $A \times B$                 \\
            $A \vee B$              & $A + B$                      \\
            $A \implies B$          & $A \to B$                    \\
            $A \iff B$              & $(A \to B) \times (B \to A)$ \\
            $\lnot A$               & $A \to \emptyt$              \\
            $\forall x \in A, P(x)$ & $\tprd{x:A} P(x)$            \\
            $\exists x \in A, P(x)$ & $\tsm{x:A} P(x)$             \\
            \thickhline                                            \\[-2.4em]
        \end{tabular}
    \end{center}
    \caption{Isomorfismo de Curry-Howard.}
    \label{table:2}
\end{table}

La correspondencia es relativamente simple por lo que no la explicaremos m\'as a detalle, solo el caso de $\lnot A$ merece una mayor atenci\'on.
En DTT el $\emptyt$ toma el rol de un absurdo, puesto que su mismo principio de inducci\'on indica que es posible formar una función con cualquier codominio dado un elemento de $\emptyt$.
Por este motivo, interpretamos $A \to \emptyt$ como $\lnot A$.

\begin{definition}
    Diremos que dos tipos $A$ y $B$ son l\'ogicamente equivalentes cuando se tiene $A \iff B$; es decir, tenemos dos funciones $f:A \to B$ y $g:B \to A$, como indicado en el Cuadro \ref{table:2}.
\end{definition}

Veamos algunos ejemplos de l\'ogica proposicional y l\'ogica predicativa.

\begin{example}
    Una de las leyes de Morgan indica que
    \[\lnot A \vee \lnot B \implies \lnot (A \wedge B) \]
    El equivalente en DTT es la existencia de una función
    \[f:  (A \to \emptyt) + (B \to \emptyt) \to (A \times B \to \emptyt) \]
    En efecto, podemos definir $f$ como
    \begin{gather*}
        f(\inl (f_1)) \defeq \lam{a,b}f_1(a) \\
        f(\inr (f_2)) \defeq \lam{a,b}f_2(b)
    \end{gather*}
\end{example}

\begin{example}
    Consideremos la siguiente implicaci\'on usada com\'unmente
    \[ \exists x \in A, \lnot P(x) \implies \lnot (\forall x \in A, P(x)) \]
    Esta es representada por la existencia de una función
    \[ f: \tsm{x : A} (P(x) \to \emptyt) \to (\tprd{x : A} P(x)) \to \emptyt \]
    Esta puede ser definida por
    \[ f((a, g), h) \defeq g(h(a)) \]
\end{example}

\begin{example}
    El axioma de elección en MC indica que dada una colección de conjuntos no vac\'ios $X$, es posible
    crear una función $f:X \to \bigcup X$ que selecciona un elemento de cada conjunto. Es decir,
    \[ \forall x \in X,  \exists y \in \bigcup x, (y \in x) \implies \exists f: X \to \bigcup X, \forall x \in X, (f(x) \in x) \]
    En DTT, esto podr\'ia ser entendido\footnote{La verdadera formalizaci\'on del axioma de elección como visto de manera cl\'asica, es ligeramente distinta a la presentaci\'on actual, ver \cite[Sección 3.8]{the_univalent_foundations_program_homotopy_2013}.} como un caso particular de
    \[ \ac : \Parens{\tprd{x:A} \tsm{y :B} R(x,y)} \to
        \Parens{\tsm{f:A\to B} \tprd{x:A} R(x,f(x))}
    \]
    Podemos definir esta función como
    \[ \ac(h) \defeq \Parens{ \lamu{x} \fst(h(x)), \lamu{ x} \snd(h(x)) } \]
    Esta función est\'a bien definida puesto que
    \begin{align*}
        \lamu{x:A} \fst(g(x)) & : A \to  B,                   \\
        \lamu{x:A} \snd(g(x)) & : \tprd{x:A} R(x,\fst(g(x))).
    \end{align*}
    como es requerido por el tipo del codomino de $\ac$.
\end{example}

\begin{definition}
    Dado un tipo $A$, si existe un elemento de \'el tal que $a:A$, diremos que $A$ es un tipo \textbf{habitado}.
\end{definition}

As\'i, se dice una proposici\'on $P$ es \textbf{verdadera} cuando es un tipo habitado.
El ejemplo previo muestra que el axioma de elección es verdadero en esta teoría.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec11
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de identidades} \label{idtype}
De acuerdo a la interpretación de proposiciones como tipos, deber\'ia haber un tipo que refleje la propiedad de estar habitado.
Este es el tipo de identidades $\id[A]{x}{y}$.

\begin{rules}
    (Reglas de formación del tipo de identidades.)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \UU_i$}
        \AxiomC{$\Gamma \vdash a : A$}
        \AxiomC{$\Gamma \vdash b : A$} \RightLabel{\footnotesize $=$-FORM}
        \TrinaryInfC{$\Gamma \vdash 0 : \N$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash A : \UU_i$}
        \AxiomC{$\Gamma \vdash a : A$}\RightLabel{\footnotesize $=$-INTRO}
        \BinaryInfC{$\Gamma \vdash \refl{a} : \id[A]{a}{a}$} \DisplayProof
    \end{center}
\end{rules}

Intuitivamente, el tipo $\id[A]{x}{y}$ representa la noción de igualdad, y este est\'a habitado justamente cuando $x$ es igual a $y$.
En particular, $\id[A]{x}{x}$ siempre est\'a habitado, puesto que contiene al elemento $\refl{x}$.
N\'otese que es imposible formar el tipo de igualdades para dos elementos en dos tipos distintos.


La introducción de este tipo permite enunciar y probar teoremas que involucren la igualdad.

\begin{example}
    Por definición, para todo $n:\N$ tenemos $0+n\defeq n$, por lo que podemos definir
    \[\lam{n}\refl{n}:\prd{n:\N}(0+n=n)\]
    Por otro lado, la demostraci\'on de $\prd{n:\N}(n+0=n)$ requiere de otros resultados, como el principio de inducción para el tipo de identidades.
\end{example}

De manera an\'aloga a los casos de la suma dependiente y el coproducto, dado que la forma can\'onica de introducir un elemento del tipo de identidades es por $\refl{x}$, basta definir una función dependiente en estos elementos para que est\'e definida en todo $\id[A]{x}{y}$.
Este razonamiento nos da:

\begin{rules}
    (Reglas de eliminaci\'on del tipo de identidades.)
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma \vdash  C : \tprd{x,y:A}(\id[A]{x}{y}) \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{x:A}C(x,x)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash a: A \hspace{2em} \Gamma \vdash b:B \hspace{2em} \Gamma \vdash p': \id[A]{a}{b}$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$=$-ELIM}}
        \TrinaryInfC{$\Gamma \vdash \ind{=_A} (C,c,a,b,p') : C(a,b,p')$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma \vdash  C : \tprd{x,y:A}(\id[A]{x}{y}) \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{x:A}C(x,x)$}
        \alwaysNoLine
        \BinaryInfC{$\hspace{4em}\Gamma \vdash a: A$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$=$-COMP}}
        \TrinaryInfC{$\Gamma \vdash \ind{=_A} (C,c,a,a,\refl{a}) : C(a,a,\refl{a})$}
        \DisplayProof
    \end{center}
\end{rules}

Como en los tipos previos, estar reglas nos dan un principio de introducción y una b\'usqueda de patrones.

\begin{theorem}
    Existe una función
    \[
        \indid{A} :  \dprd{C : \prd{x,y:A} (\id[A]{x}{y}) \to \UU}
        \Parens{\tprd{x:A} C(x,x,\refl{x})} \to
        \dprd{x,y:A}{p:\id[A]{x}{y}}   C(x,y,p)
    \]
    tal que
    \[ \indid{A}(C,c,x,x,\refl{x}) \defeq c(x). \]
\end{theorem}

\begin{proof}
    Inmediato de las reglas.
\end{proof}

\begin{notation}
    (B\'usqueda de patrones para el tipo de identidades)\\
    Podemos definir una función $f : \dprd{x,y:A}{p:\id[A]{x}{y}}   C(x,y,p)$ definiendo su comportamiento en $\refl{x}$, es decir
    \[ f(\refl{x}) \defeq \Phi : C(x,x,\refl{x}) \]
\end{notation}

\begin{justification}
    $f$ puede ser definida como
    \[ f\defeq \indid{A} (C,\lam{x}\Phi)\]
\end{justification}

El tipo de identidades es quiz\'as el que mayor riqueza trae a esta teor\'ia, y el siguiente cap\'itulo estar\'a dedicado principalmente a este.
\begin{notation}
    Escribiremos $x=y$ en vez de $\id[A]{x}{y}$ cuando no haya riesgo de confusión.
\end{notation}

Para diferenciar el tipo $\id[A]{x}{y}$ del juicio $x \jdeq y$, a veces se llama al primero de estos como una \textbf{igualdad proposicional}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec_
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Grupos}
Veamos como los tipos introducidos nos permiten formalizar en DTT el concepto de un grupo.
Recordemos que en MC un grupo es par $(G, *)$, tal que $G$ es un conjunto y $*$ es una operaci\'on binaria en $G$ tal que
\begin{itemize}
    \item $*$ es asociativa,
    \item existe un elemento neutro $e$, tal que para todo $g \in G$ se tiene que $e * g = g * e = g$, y
    \item para todo $g \in G$ existe un $g^{-1} \in G$ tal que $g*g^{-1}=g^{-1}*g=e$.
\end{itemize}

Esta estructura puede ser reflejada directamente en la siguiente definici\'on
\begin{definition}
    Dado un tipo $A$, diremos que este tiene una \textbf{estructura de grupo} si es que el tipo
    \begin{align*}
        \mathsf{GroupStr}(A) \defeq \sm{m:A\to A \to A} & \prd{x,y,z:A} \left( m(x,m(y,z))=m(m(x,y),z) \right) \\
        \times                                          & \sm{e:A } (e * g = g) \times (g * e = g)             \\
        \times                                          & \sm{i:A \to A} (g * i(g) = e) \times (i(g) * g = e)
    \end{align*}
    est\'a habitado.
\end{definition}
Cada l\'inea de la definici\'on previa corresponde a uno de los puntos de la definici\'on cl\'asica.
Con el concepto de estructura ya definido, podemos definir lo que es un grupo.

\begin{definition}\label{Groups}
    Un \textbf{grupo} es un tipo junto con una estructura de grupo. Es decir, un elemento del tipo
    \[ \mathsf{Group} \defeq \sm{A: \UU}\mathsf{GroupStr}(A) \]
\end{definition}

N\'otese que, a diferencia de MC, s\'i tenemos un tipo de todos los grupos, el cual es $\mathsf{Group}$.

Es claro que una formalizaci\'on similar aplica para la gran mayor\'ia de teor\'ias algebraicas, como las de los anillos, m\'odulos, categor\'ias, etc.


%%%% sec12
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metateor\'ia}
Hemos introducido las reglas de DTT que usaremos en lo que sigue del presente documento.
En la presente sección discutiremos sobre las reglas mismas, y sobre las propiedades de la teor\'ia que estas generan; es decir, la \textit{metateor\'ia}.

En primer lugar, parecer\'ia que existe cierta inconsistencia en algunas reglas. Por ejemplo, consideremos la siguiente regla ya introducida

\begin{center}
    \AxiomC{$\Gamma \vdash a:A$}
    \UnaryInfC{$\Gamma \vdash a\equiv a:A$} \DisplayProof \hspace{2em}
\end{center}

Se tiene $\Gamma \vdash a:A$ en la hipótesis; sin embargo, no estamos afirmando que $A$ sea un tipo, por lo que podr\'ia ser posible que $a:A$ sea una expresión sin sentido.

Esta inquietud, aunque v\'alida, no est\'a justificada, pues tenemos el siguiente resultado.

\begin{theorem}
    Si se tiene {$\Gamma \vdash a:A$} para alg\'un $\Gamma$, también se tiene que $\Gamma \vdash A:\UU_i$.
\end{theorem}

N\'otese que a diferencia de los resultados y ejemplos previos, este resultado es un resultado sobre la teoría misma.
Los teoremas de incompletitud de G\"odel \cite{godel_uber_1931} est\'an en este mismo nivel.

\begin{proof}
    La t\'ecnica a través la cual se muestran este tipo de teoremas en DTT es a través de \textit{inducción estructural}.
    Recordemos que una derivación de un juicio es en realidad un \'arbol invertido con el juicio por derivar en la ra\'iz del \'arbol.
    Por lo tanto, podemos utilizar inducción en el \'arbol, de acuerdo a la \'ultima regla usada para llegar a $\Gamma \vdash a:A$.

    Por ejemplo, si la \'ultima regla usada fue $\N$-INTRO$_1$, tenemos que $\Gamma \vdash 0:\N$, y por $\N$-FORM sabemos que $\N$ es un tipo.
    Un razonamiento an\'alogo por casos para cada regla relevante concluye la demostraci\'on.
\end{proof}

Otros dos resultados importantes, que ya hemos utilizado libremente en los ejemplos son:

\begin{theorem}(Substituci\'on)
    Si se tiene $\Gamma \vdash a : A$ y $\Gamma , x:A , \Delta \vdash b :B$, entonces es posible derivar $\Gamma, \Delta [a/x] \vdash b[a/x] : B[a/x]$.
\end{theorem}
\begin{theorem}(Debilitaci\'on)
    Si se tiene $\Gamma \vdash A : \UU_i$ y $\Gamma , \Delta \vdash b :B$, entonces es posible derivar $\Gamma, x:A, \Delta \vdash b:B$.
\end{theorem}

La demostración de estos teoremas  para teor\'ias similares se puede encontrar en \cite{pierce_types_2002}, por ejemplo.

El \'ultimo metateorema que presentaremos sobre DTT es que esta teor\'ia es consistente, es decir no se puede derivar una contradicción a partir de las reglas ya introducidas.

\begin{theorem}\label{cons-dtt}(Consistencia de DTT)
    No es posible derivar una contradicción en DTT, es decir $\cdot \vdash x : \emptyt$ para alg\'un $x$; asumiendo que la teor\'ia usual de MC tambi\'en es consistente.
\end{theorem}

Omitimos también la demostración de este resultado, que se puede encontrar en \cite{martin-lof_intuitionistic_1984}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec13
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Comentarios adicionales}
\subsection*{La complejidad de DTT}
La introducción de las reglas y la derivación de juicios podr\'ia hacer parecer que DTT es una teor\'ia mucho m\'as complicada que la l\'ogica cl\'asica; sin embargo, este no es el caso.
La l\'ogica cl\'asica en realidad también est\'a formalizada de una forma similar, por ejemplo se tiene la siguiente regla para la introducción de la conjunci\'on:

\begin{center}
    \AxiomC{$\varphi$}
    \AxiomC{$\psi$} \RightLabel{\footnotesize  $\wedge$-INTRO}
    \BinaryInfC{$\varphi \wedge \psi$}  \DisplayProof
\end{center}

As\'i existen reglas para cada constructo l\'ogico ($\forall, \exists, \wedge, \vee, \neg, \implies$), y resultados an\'alogos a los de la sección previa \cite{chiswell_mathematical_2007}, los cuales son asumidos implicitamente por los matemáticos, raz\'on por lo que omitimos las  para DTT.

La diferencia es entonces que las reglas de la l\'ogica cl\'asica son usualmente introducidas de manera informal, mientras que hemos decidido presentar las reglas de DTT formalmente en este trabajo.
Diversas presentaciones de DTT introducen los constructos de forma informal, como \cite{nordstrom_programming_1990} y \cite{friedman_little_2018}.

\subsection*{Constructivismo}
La l\'ogica subyacente en DTT es una l\'ogica \textbf{constructiva}, también llamada \textbf{l\'ogica intuicionista}.
Por ejemplo, en esta no es posible demostrar $P \vee \neg P$, la ley del medio excluido.
Es posible a\~nadir esta ley como una regla adicional\footnote{Esto es posible en DTT, pero una vez introducido el axioma de univalencia esto se vuelve inconsistente. En cambio, se puede introducir un axioma similar, que solo involucra proposiciones simples (ver Sección \ref{hprops}).}, pero esto no ser\'a necesario en el desarrollo actual.

Ante cierta inspecci\'on, es f\'acil notar que esta ley es en cierto sentido problem\'atica.
Esta permite afirmar la existencia de objetos que no han sido construidos expl\'icitamente, o simplificar problemas de una forma no obvia. Por ejemplo, consideremos la siguiente proposici\'on:

\begin{proposition}
    Existe un n\'umero natural $n$, tal que $n=0$ si y solo si la hipótesis de Riemann es verdadera.
\end{proposition}

\begin{proof}
    Si la hipótesis de Riemann es verdadera, entonces $n$ es 0. Si la hipótesis de Riemann es falsa, entonces podemos poner $n=1$.
\end{proof}

Este n\'umero $n$ refleja la veracidad de la hip\'otesis de Riemann de una forma no obvia.
Por otro lado, si la prueba fuese constructiva, habr\'iamos generado un $n$ espec\'ifico, y podr\'iamos verificar f\'acilmente si este es o no diferente de 0.

No asumir la ley del medio excluido significa que todos los elementos de los cuales tenemos informaci\'on has sido construidos paso a paso, por lo que adem\'as de su existencia, podemos indagar sobre otras propiedades relevantes que pueden tener.

Otro principio relacionado es el de reducci\'on al absurdo, $\neg \neg P \implies P$.
Este es en realidad equivalente a la ley del medio excluido, y permite probar la existencia de elementos sin saber cu\'ales son. Por ejemplo:

\begin{proposition}
    En la expansi\'on decimal de $\pi$, existen dos d\'igitos que se repiten infinitas veces.
\end{proposition}

\begin{proof}
    Si no fuese as\'i, se tendr\'ia que un solo d\'igito se repite infinitas veces, o que ning\'un d\'igito se repite infinitas veces. En ambos casos, concluimos que $\pi$ es un racional, lo cual es un absurdo.
\end{proof}

Sin embargo, en esta prueba no hemos hallado cu\'ales son estos dos d\'igitos; es decir, la prueba no es constructiva.

Esto no quiere decir que no podamos utilizar nunca el razonamiento de $P \vee \lnot P$, solo que para utilizarlo es necesario primeramente demostrar que esto se cumple para el tipo $P$ en cuesti\'on. Realizaremos esto para las igualdades en los naturales en la Secci\'on \ref{natpaths}.

\subsection*{Asistentes de pruebas}

Incluso grandes matemáticos como Leibniz, Gauss, Andrew Wiles, entre otros, han cometido graves errores en sus demostraciones, y ellos no fueron los primeros ni ser\'an los \'ultimos.
A fin de evitar esto, existen los llamados \textbf{asistentes de pruebas}, programas que verifican que una demostración es correcta.
La mayor\'ia de estos usan DTT en vez de teor\'ia de conjuntos, consideremos el siguiente ejemplo tomado de \cite{376973} para ver por qu\'e:

\begin{proposition}
    Sean $U$ y $V$ espacios vectoriales y $f:U \to V$ una función lineal. Entonces $f(2x+y)=2f(x)+f(y)$.
\end{proposition}

La proposici\'on es f\'acilmente entendida por un lector que conozca estos conceptos, y pareciese que se ha presentado con precisión los variables necesarias, pero veamos la gran cantidad de informaci\'on omitida:

\begin{itemize}
    \item Se ha entendido que existe un campo $K$ subyacente a $U$ y a $V$.
    \item Se ha entendido que $f$ es en realidad una función entre los conjuntos subyacentes $f: |U| \to |V|$, recordemos que un espacio vectorial $U$ es un triple $(|U|,\cdot,+)$.
    \item Se ha entendido que $x$ y $y$ son elementos arbitrarios de $|U|$.
    \item Se ha entendido que el `$+$' en la izquierda de la ecuaci\'on es la suma asociada a $U$, mientras que el `$+$' en la derecha es el asociado a $V$.
    \item Finalmente, se ha entendido que $2$ es $1+1$, donde $1$ es el neutro de la multiplicaci\'on del campo $K$.
\end{itemize}

Esta gran cantidad de informaci\'on no puede ser inferida correctamente por computadoras que formalicen la teor\'ia de conjuntos.
Uno de los principales problemas es que la estructura que tiene cierto constructo, como los espacios vectoriales, no es reflejada de una manera \'unica en teor\'ia de conjuntos.
Por poner otro ejemplo, dada la construcci\'on de los reales como cortes de Dedekind, no solo tiene sentido la proposici\'on `$0_\Q \in 1_\R$'; peor a\'un, es verdadera.

En contraste, en DTT, los elementos de un tipo pertenecen a un \'unico tipo (a excepción de los tipos mismos), y la estructura adicional es parte esencial y \'unica de una definición (ver \ref{Groups}, por ejemplo).
Estos hechos permiten la inferencia del significado de variables no completamente especificadas, en la gran mayor\'ia de los casos.
Esto hace que DTT sea una teor\'ia m\'as apropiada para la formalizaci\'on de las matemáticas, a trav\'es de programas de computadoras.

Ya existe un gran esfuerzo a nivel global de traducir la matemática cl\'asica al lenguaje de DTT, usado por los asistentes de pruebas, y as\'i permitir la verificaci\'on de estos resultados por computadora.
Entre estos, mencionamos las formalizaciones \cite{mahboubi_mathematical_2021} y \cite{the_mathlib_community_lean_2020}, proyectos con m\'as de 250 contribuidores en conjunto.

Gran parte de resultados que consideramos b\'asicos, y que se ense\~nan a nivel de pregrado ya est\'an formalizados.
Sin embargo, tambi\'en se han verificado algunos resultados m\'as modernos y complicados.
El teorema de Feit-Thompson \cite{1103053943}, que indica que todo grupo de orden finito e impar es soluble, fue verificado usando el programa Coq en el 2013 \cite{ftcoq2013}.

Otro ejemplo es la verificaci\'on de un resultado avanzado de geometr\'ia algebraica de Peter Scholze, ganador del premio Fields 2018, en colaboraci\'on con Dustin Clausen.
El proceso de formalizaci\'on comenz\'o como un reto de Scholze a la comunidad de asistentes de pruebas \cite{scholze_2020}:
\begin{displayquote}
    Considero que este teorema es de una gran importancia fundacional, por lo que estar 99.9\% seguro no es suficiente\ldots\
    Pas\'e mucho del 2019 obsesionado con la prueba de este teorema, casi volvi\'endome loco sobre esta. Al final logramos escribir el argumento en un art\'iculo, pero creo que nadie m\'as se ha atrevido a ver los detalles de este, as\'i que todav\'ia tengo algunas peque\~nas dudas.
\end{displayquote}

Solo 6 meses despu\'es, con la ayuda de varios matem\'aticos y cient\'ificos de la computaci\'on, Scholze escribe que su reto era pr\'acticamente un \'exito: aunque todav\'ia no se hab\'ia demostrado el teorema, todos los lemas que causaban cierta duda ya estaban formalizados \cite{scholze_half_2021}.
A trav\'es de este ejercicio, \'el comenta, no solo encontr\'o m\'ultiples errores (que afortunadamente fueron posibles de solucionar), tambi\'en profundiz\'o el entendimiento de su propia prueba.

Esta es la propuesta de los proponentes de los asistentes de pruebas: introducir a las computadoras como una herramienta m\'as en el arsenal que posee un matem\'atico, y obtener una mejor comprensi\'on del tema de estudio, as\'i como la posibilidad de no volver a equivocarnos nunca m\'as\footnote{Podr\'ia preguntarse uno, ?`qu\'e garantiza que el programa no cometa un error? La respuesta es: matemática. Se puede razonar de una forma similar a la de inducción estructural, y verificar que cada paso del programa es correcto, y por lo tanto, el algoritmo entero.}.

El presente trabajo advoca esta posici\'on, por lo que todos los resultados aqu\'i descritos has sido formalizados en un asistente de pruebas, llamado Agda.
El c\'odigo se encuentra disponible en l\'inea, a trav\'es de la siguiente p\'agina web interactiva \url{https://ryunaq.github.io/MastersThesis/}.

Enfatizamos que la posibilidad de la formalizaci\'on en un asistente de pruebas es solo una ventaja m\'as de DTT.
Como mencionamos, la ventaja principal es el tratamiento uniforme de proposiciones y tipos, la cual ser\'a aprovechada en los siguientes cap\'itulos.

\end{document}
