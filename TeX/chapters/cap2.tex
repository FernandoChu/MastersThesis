\documentclass[../main.tex]{subfiles}
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
En este cap\'itulo daremos una descripción formal y rigurosa de la Teoría de Tipos Dependientes (DTT, en adelante, por sus siglas en inglés), haciendo una comparación a la Matemática Clásica (MC, en adelante) cuando sea conveniente.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Expresiones, términos y contextos}
Dado que las proposiciones y las demostraciones son objetos mismos en DTT, es necesario tener mayor precisión respecto a los significados de ciertos términos.
\begin{definition}
    Una \textbf{signatura} $Sg$ es una colección de símbolos tipográficos. Una \textbf{expresión} $Exp_{Sg}$ es una secuencia finita de símbolos provenientes de la signatura $Sg$.
\end{definition}
\begin{example}
    La Matem\'atica Cl\'asica utiliza como signatura la colección que contiene a los caracteres alfanuméricos, los conectores lógicos y a los operadores; es decir,
    \[Sg=\{\textrm`1\textrm',\textrm`(\textrm',\textrm`n\textrm',\textrm`{+}\textrm',\textrm`\Sigma\textrm',\textrm`x_i\textrm',\dots\}.\]
    Una expresión típica de MC es $\langle \textrm`1\textrm', \textrm`{+}\textrm', \textrm`1\textrm', \textrm`{=}\textrm', \textrm`2\textrm' \rangle_{Sg}$.
\end{example}
\begin{notation}
    Asumiremos siempre que esta misma signatura está implícita en todas las próximas expresiones que escribamos. Además, las expresiones se escribirán sin comillas, sin corchetes y sin hacer referencia a esta signatura.
\end{notation}
\begin{justification}
    Puesto que la signatura será la misma para el resto de este documento y dado que existe una sola forma de interpretar una expresión simplificada
    como una secuencia de caracteres, no habrá riesgo de ambigüedad.
\end{justification}

La justificación de esta notación es simple, pero se ha dado para enfatizar que \textit{alguna} justificación es necesaria. En las próximas notaciones, omitiremos las justificaciones triviales y solo justificaremos las más complicadas de realizar.

Para nuestras pr\'oximas definiciones, necesitaremos el siguiente concepto.

\begin{definition}
    Una \textbf{metavariable} es una variable que puede tomar como valor cualquier expresi\'on, a excepción de aquellas que contienen alguno de los s\'imbolos `\equiv', `:', `\vdash' o `ctx'.
\end{definition}

La raz\'on por la que omitimos estos cuatro s\'imbolos de la definici\'on es porque estos son \textit{caracteres reservados}, los cuales tienen un significado particular y ser\'an introducidos en la pr\'oxima secci\'on.

\begin{definition}
    Sean $a$ y $A$ metavariables, dada una expresión de la forma
    $((a):(A))$, diremos que $A$ es un \textbf{tipo} y que $a$ es un \textbf{término} o \textbf{elemento} del tipo $A$.
\end{definition}
\begin{example}
    En la expresión $((2+n):(\N))$, $\N$ es un tipo y $(2+n)$ es un término de tipo $A$.
\end{example}
\begin{notation}
    En la mayoría de casos, omitiremos los paréntesis, entendiendo que el símbolo `${:}\textrm'$ tiene menor precedencia que otros símbolos por introducir, a excepción de los símbolos `${,}\textrm'$ (en contextos), y `${\vdash}\textrm'$ y  `${\textnormal{ctx}}\textrm'$ (en juicios).
\end{notation}

Para el resto de este documento utiliaremos metavariables sin mencionar que lo son, dejando la tarea de discernirlas al lector.

Existen ciertas semejanzas entre $a:A$ en DTT y $a \in A$ en MC, pero también hay algunas diferencias importantes.
Primero, $a$ no es un elemento que existe independientemente de $A$; es decir, un término siempre debe estar acompañado del tipo al que corresponde.
Relacionado a esto, un término pertenece únicamente a un tipo (con una excepción, ver Sección \ref{universes}), mientras que en teoría de conjuntos un elemento puede pertenecer a varios conjuntos.

\begin{definition}
    Un \textbf{contexto} es una lista finita de expresiones de la forma $a:A$. Es decir, un contexto es una expresión de la forma
    $$\langle x_1{:}A_1, \, x_2{:}A_2, \, \dots, \, x_n{:}A_n\rangle.$$
    Los $x_i$ son llamados \textbf{variables}.
\end{definition}
\begin{example}
    La expresión $\langle n{:}\N,v{:}\R^n,M{:}\R^{n\times n}, Mv{:}\R^n \rangle$ es un contexto.
\end{example}
\begin{notation}
    Omitiremos siempre los corchetes, entendiendo que los símbolos `${,}\textrm'$ en la lista tienen menor precedencia que otros símbolos por introducir, a excepción de los símbolos `${\vdash}\textrm'$ y  `${\textnormal{ctx}}\textrm'$ en juicios. Además, denotamos el contexto vac\'io con el símbolo `${\cdot}\textrm'$.
\end{notation}

Nótese que las expresiones y los contextos pueden no estar bien formadas; es decir, pueden ser una secuencia de símbolos sin significado alguno, como $\int 0/0 : \sin \Q$.
Los juicios evitan este problema.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Juicios y reglas de inferencia}
\begin{definition}
    Sea $\Gamma$ es un contexto, un \textbf{juicio} es una expresión de una de las tres siguientes formas:
    $$(\Gamma) \textnormal{ ctx} \hspace{4em}  (\Gamma) \vdash (a:A) \hspace{4em}  (\Gamma) \vdash (a\equiv a':A)$$
\end{definition}
\begin{notation}
    Omitiremos siempre los paréntesis, entendiendo que los símbolos `${\vdash}\textrm'$ y `${\textnormal{ctx}}\textrm'$ tienen menor precedencia que todos los otros símbolos. En el caso de los últimos dos tipos de juicios, omitiremos la mención del contexto $\Gamma$ y el símbolo $\vdash$ cuando el contexto no sea relevante o este implícito.
\end{notation}

La noción de juicios en DTT toma un rol similar al de proposiciones en MC. El significado de estos juicios es detallado en el siguiente cuadro.
\begin{table}[H]
    \begin{center}
        \begin{tabular}{ l l }
            \thickhline
            Juicio                       & Interpretaci\'on                                                                                            \\
            \hline
            $\Gamma \text{ ctx}$         & \parbox[t]{9cm}{\begin{spacing}{1}
                                                                   $\Gamma$ es un contexto bien formado; es decir, una lista de suposiciones bien formadas.
                                                               \end{spacing}}     \\[1.4em]
            $\Gamma \vdash a:A$          & \parbox[t]{9cm}{\begin{spacing}{1}
                                                                   El contexto $\Gamma$ implica que $a$ es un elemento del tipo $A$.
                                                               \end{spacing}}                            \\[.3em]
            $\Gamma \vdash a\equiv a':A$ & \parbox[t]{9cm}{\begin{spacing}{1}
                                                                   El contexto $\Gamma$ implica que $a$ y $a'$ son objetos iguales por definición del tipo $A$.
                                                               \end{spacing}} \\
            \thickhline                                                                                                                                \\[-2.4em]
        \end{tabular}
    \end{center}
    \caption{Juicios en DTT y su significado.}
    \label{table:1}
\end{table}

Notamos que el tercer tipo de juicios se refiere solo a igualdades por definición, en la Sección \ref{idtype} introduciremos otra noción de igualdad. Por otro lado, los primeros dos juicios formalizan la noción de que una expresión tenga ``sentido''.

\begin{definition}
    Una expresión de la forma $a$ se dice \textbf{bien tipada} si es que existe un contexto $\Gamma$ y un tipo $A$ tal que $\Gamma \text{ ctx}$ y $\Gamma \vdash a:A$.

    Similarmente, una expresi\'on de la forma $b:B$ se dice \textbf{bien tipada} si es que existe un contexto $\Gamma$ tal que $\Gamma \text{ ctx}$ y $\Gamma \vdash b:B$.
\end{definition}

De esta manera, veremos que la expresión previa, $\int 0/0 : \sin \Q$, no est\'a bien tipada.
Para llegar a esta conclusión, debemos entender el proceso a través del cual llegamos a estos juicios: la aplicación de reglas de inferencia.

\begin{definition}
    Una \textbf{regla de inferencia} es de la forma
    \begin{prooftree}
        \AxiomC{$\mathcal H_1$}
        \AxiomC{$\cdots$}
        \AxiomC{$\mathcal H_k$} \RightLabel{\footnotesize{NOMBRE}}
        \TrinaryInfC{$\mathcal C$}
    \end{prooftree}
    donde $\mathcal H_1, \dots, \mathcal H_k$ y $\mathcal C$ son expresiones. Las expresiones $\mathcal H_1, \dots, \mathcal H_k$ son llamadas \textbf{hipótesis}, mientras que $\mathcal C$ es llamada la \textbf{conclusión}.
\end{definition}

Escribimos a la derecha el nombre de la regla, para ser referenciada posteriormente.
Cabe notar que una regla puede tener restricciones adicionales que deben ser corroboradas antes de poder ser aplicada.
Si la lista de hipótesis es muy larga, las apilaremos unas sobre otras (ver Reglas \ref{coprodelim}).
Las reglas toman un rol similar al de la deducci\'on l\'ogica en MC.

\begin{definition}
    Una \textbf{derivación} de un juicio es un árbol invertido con el juicio por derivar en la raíz del árbol, donde el paso de un nodo a otro nodo está justificado por una regla de inferencia.
\end{definition}

\begin{example}
    Con las reglas que presentaremos posteriormente, el siguiente árbol es una derivación de $\cdot \vdash \textbf{0} + \textbf{1} : \mathcal{U}_0$.
    \begin{prooftree}
        \def\ScoreOverhang{1pt} \def\extraVskip{3pt}  \def\defaultHypSeparation{\hskip .5in}
        \AxiomC{}\RightLabel{\footnotesize ctx-EMP}
        \UnaryInfC{$\cdot$ ctx} \RightLabel{\footnotesize{$0$-FORM}}
        \UnaryInfC{$\cdot \vdash \textbf{0} : \mathcal{U}_0$}
        \AxiomC{}\RightLabel{\footnotesize ctx-EMP}
        \UnaryInfC{$\cdot$ ctx} \RightLabel{\footnotesize{$1$-FORM}}
        \UnaryInfC{$\cdot \vdash \textbf{1} : \mathcal{U}_0$} \RightLabel{\footnotesize $+$-FORM}
        \BinaryInfC{$\cdot \vdash \textbf{0} + \textbf{1} : \mathcal{U}_0$}
    \end{prooftree}
\end{example}

Con los conceptos previos ya definidos, comenzaremos a introducir las reglas de inferencias de DTT.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Universos} \label{universes}
Como mencionamos previamente, todo término es un elemento de un tipo.
Para ser manipulados efectivamente, estos, a su vez, son elementos de otro tipo.
\begin{definition}
    El tipo de un tipo es llamado un \textbf{universo}.
\end{definition}
A fin de evitar la paradoja de Russell\footnote{La paradoja de Russell \cite{russell_principles_2020} es la siguiente: sea $X$ el conjunto de todos los conjuntos que no se contienen a s\'i mismos. Si $X$ se contiene a s\'i mismo, no deber\'ia de contenerse a s\'i mismo por definici\'on. Si $X$ no se contiene a s\'i mismo, s\'i deber\'ia de hacerlo por definici\'on. Entonces ambos casos llevan a una contradicción.}, un universo no es un elemento de sí mismo.
Al contrario, existe una infinita jerarquía de universos, la cual se ve formalizada en las siguientes reglas.
\begin{rules}
    (Reglas básicas de universos)
    \begin{center}
        \AxiomC{$\Gamma$ ctx}\RightLabel{\footnotesize  $\mathcal{U}_i$-INTRO}
        \UnaryInfC{$\Gamma \vdash  \mathcal{U}_i:  \mathcal{U}_{i+1}$}  \DisplayProof \hspace{3em}
        \AxiomC{$\Gamma \vdash  A:  \mathcal{U}_{i}$}\RightLabel{\footnotesize  $\mathcal{U}_i$-CUMUL}
        \UnaryInfC{$\Gamma \vdash  A :  \mathcal{U}_{i+1}$}  \DisplayProof
    \end{center}
\end{rules}

La primera regla indica que si $\Gamma$ es un contexto bien formado, entonces $\Gamma$ implica que el universo $\mathcal{U}_i$ es un elemento del universo $\mathcal{U}_{i+1}$.
La segunda regla indica que si $\Gamma$ implica que $A$ es un elemento del universo $\mathcal{U}_{i}$, entonces $\Gamma$ implica que $A$ también es un elemento del universo $\mathcal{U}_{i+1}$.

Dado que son las primeras reglas introducidas, hemos brindado una interpretaci\'on de ellas.
Para las próximas reglas no realizaremos este tipo de comentarios, salvo para aclarar alguna posible confusión.
La lista completa de reglas presentadas en esta secci\'on se encuentra en el Apéndice \ref{reglas}.

\begin{notation}
    Omitiremos los subíndices de los universos en la mayoría de escenarios, por lo que interpretaremos expresiones sin sentido como $\mathcal U: \mathcal U$ agregando índices adecuados, obteniendo $\mathcal{U}_i: \mathcal{U}_{i+1}$.
    Esta práctica puede traer inconsistencias si no es manejada con precisión, pero la usaremos igualmente para reducir la carga notacional.
\end{notation}

Nótese que los subíndices no son elementos del tipo de los naturales, sino son parte del símbolo `$\UU_i$'; es decir, consideramos a `$\UU_i$' como un solo caracter.
Por este motivo, expresiones como $n:\N \vdash A: \mathcal U_n$ no están bien formadas.

Con los universos ya definidos, introducimos las reglas respecto a la formación de contextos.
\newpage

\begin{rules}
    (Reglas básicas de contextos y variables)
    \begin{center}
        \AxiomC{}\RightLabel{\footnotesize ctx-EMP}
        \UnaryInfC{$\cdot$ ctx} \DisplayProof \hspace{3em}
        \AxiomC{$x_1{:}A_1, \dots,x_{n-1}{:}A_{n-1} \vdash A_n:\mathcal{U}_i$}\RightLabel{\footnotesize ctx-EXT}
        \UnaryInfC{$(x_1{:}A_1, \dots,x_n{:}A_n$) \text{ctx}}  \DisplayProof\\[.8em]
        \AxiomC{$(x_1{:}A_1, \dots,x_n{:}A_n$) \text{ctx}}  \RightLabel{\footnotesize Vble}
        \UnaryInfC{$x_1{:}A_1, \dots,x_n{:}A_n \vdash x_i:A_i$}  \DisplayProof
    \end{center}
    donde la regla ctx-EXT tiene la condición adicional de que la variable $x_n$ debe ser distinta a las demás variables $x_1, \dots,x_{n-1}$, y la regla Vble requiere que $1 \leq i \leq n$.
\end{rules}

N\'otese que la regla ctx-EMP tiene 0 hipótesis, por lo que siempre es posible aplicarla.
A continuaci\'on, detallamos el comportamiento de igualdades por definición.

\begin{rules}
    (Reglas básicas de igualdades por definición)
    \begin{center}
        \AxiomC{$\Gamma \vdash a:A$}
        \UnaryInfC{$\Gamma \vdash a\equiv a:A$} \DisplayProof \hspace{2em}
        \AxiomC{$\Gamma \vdash a \equiv b:A$}
        \UnaryInfC{$\Gamma \vdash b\equiv a:A$} \DisplayProof \hspace{2em}
        \AxiomC{$\Gamma \vdash a \equiv b:A$}
        \AxiomC{$\Gamma \vdash b \equiv c:A$}
        \BinaryInfC{$\Gamma \vdash a\equiv c:A$} \DisplayProof  \\[1.2em]
        \AxiomC{$\Gamma \vdash a :A$}
        \AxiomC{$\Gamma \vdash A \equiv B : \mathcal{U}_i$}
        \BinaryInfC{$\Gamma \vdash a:B$} \DisplayProof \hspace{1.5em}
        \AxiomC{$\Gamma \vdash a \equiv b :A$}
        \AxiomC{$\Gamma \vdash A \equiv B : \mathcal{U}_i$}
        \BinaryInfC{$\Gamma \vdash a \equiv b : B$} \DisplayProof
    \end{center}
\end{rules}

Las tres primeras reglas de $\equiv$ indican que esta es una relación de equivalencia, mientras las otras formalizan el buen comportamiento de juicios respecto a tipos iguales por definición.

En las siguientes secciones introduciremos reglas para la formación, introducción y eliminación de algunos constructos.
Para cada una de estas reglas, existe una regla correspondiente indicando que estas reglas preservan la igualdad por definición.
Como es com\'un en la presentaci\'on de reglas de DTT, estas ser\'an omitidas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de funciones}
El concepto de una funciones es fundamental en las diferentes \'areas de investigaci\'on de la Matem\'atica Cl\'asica, en esta sección presentaremos la versión análoga a esta noción en Teoría de Tipos Dependientes.

\begin{definition}
    Dados dos tipos $A$ y $B$, el tipo $A \to B$ es llamado el \textbf{tipo de funciones} de $A$ a $B$. Un elemento $f:A \to B$ es llamado una \textbf{función}. En este caso, decimos que $A$ es el \textbf{dominio} de $f$ y $B$ es el \textbf{codominio} de $f$.
\end{definition}

Intuitivamente, para construir una función $f:A \to B$, es suficiente que, dado $x:A$, podamos generar una expresión $b:B$ que est\'e bien definida, donde $b$ puede contener la variable $x$ dentro de ella.
Esto sugiere las siguientes reglas.

\begin{rules}
    (Reglas de formación de funciones)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \mathcal{U}_i$}
        \AxiomC{$\Gamma \vdash B : \mathcal{U}_i$} \RightLabel{\footnotesize $\to$-FORM}
        \BinaryInfC{$\Gamma \vdash A \to B : \mathcal{U}_i$} \DisplayProof  \hspace{1.8em}
        \AxiomC{$\Gamma, x:A \vdash b :B$}  \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma \vdash \lam{x:A}b : A \to B$}  \DisplayProof
    \end{center}
\end{rules}

La expresión $\lam{x:A}b$ puede entenderse como la función $f:A \to B$ definida por $f(x)=b$, solo que se ha omitido el nombre $f$.
Por este motivo, a veces en la literatura estas funciones se llaman funciones anónimas.
En este documento nosotros las llamaremos funciones lambda, el nombre original que les dio Alonzo Church \cite{church_set_1932}.

En la expresión $\lam{x:A}b$, se dice que $x$ es una \textbf{variable ligada} en $b$.
Esto es similar a c\'omo las expresiones `'$\forall x$' o `'$\int -  \, \text{dx}$' ligan la variable $x$ dentro de estas.
Si una variable no es ligada, se dice que es una \textbf{variable libre}.

Si $f$ es una función de $A$ en $B$, entonces podemos aplicarla a un elemento $a:A$ para conseguir un elemento de $b:B$.
Intuitivamente, esto se da reemplazando todos las apariciones de $x$ por $a$.
Este proceso se ve formalizado a trav\'es de las siguientes reglas.

\begin{rules}
    (Reglas de aplicación de funciones)
    \begin{center}
        \AxiomC{$\Gamma \vdash f : A\to B$}
        \AxiomC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\to$-ELIM}
        \BinaryInfC{$\Gamma \vdash f(a) : B$} \DisplayProof  \\[.8em]
        \AxiomC{$\Gamma, x:A \vdash b: B$}
        \AxiomC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\to$-COMP}
        \BinaryInfC{$\Gamma \vdash (\lam{x:A}b)(a) \equiv b[a/x] : B$} \DisplayProof
    \end{center}
    donde la expresión $b[a/x]$ indica que reemplazaremos todas las apariciones libres de $x$ con $a$.
\end{rules}

N\'otese que la regla $\to$-COMP implica que la imagen de una funci\'on es \'unica, mientras que en MC una funci\'on se define como una relaci\'on que cumple esta propiedad.

\begin{example}
    Para este ejemplo, asumiremos la existencia del tipo de los naturales $\N$, el cual ser\'a introducido posteriormente.

    Formaremos la función identidad en $\N$ y la aplicaremos en 0.
    Sea $\Gamma$ igual a $\N{:}\UU$, entonces
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, n{:} \N$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, n{:}\N \vdash n:\N$}  \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma \vdash \lam{n:\N}n : \N \to \N$}  \DisplayProof
    \end{center}
    Esto muestra que la función existe y tiene el tipo adecuado. Sea $\Gamma$ igual a $\N{:}\mathcal{U}, 0{:}\N$, veremos que la función se comporta adecuadamente
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, n{:} \N$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, n{:}\N \vdash n: \N$}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma \vdash 0:\N$} \RightLabel{\footnotesize $\to$-COMP}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma \vdash (\lam{n:\N}n)(0) \equiv n[0/n] : \N$}
        \UnaryInfC{$\Gamma \vdash (\lam{n:\N}n)(0) \equiv 0 : \N$} \DisplayProof
    \end{center}
\end{example}

\begin{definition}
    Sea $A$ un tipo, la función identidad $\idfunc[A]:A\to A$ está definida por $$\idfunc[A]\defeq \lam{x:A}x$$
\end{definition}

\begin{notation}
    Usaremos el símbolo $\defeq$ para dar definiciones. Una definición debe considerarse solo como una abreviación.
    El símbolo $\defeq$ no pertenece a DTT per se, sino solo es un mecanismo para reducir la notación en la práctica matemática.
\end{notation}

Como mencionamos en la introducción, ya esta función simple representa una mejora respecto a MC. Dado el tipo de todos los conjuntos $\mathsf{Set}$, la función $\idfunc[\mathsf{Set}]$ es la función identidad en todos los conjuntos, un concepto imposible de formalizar en MC.

\begin{notation}
    Omitiremos a veces el tipo de una expresión y su contexto asociado, cuando estos no sean relevantes o sean posibles de inferir fácilmente. De esta forma, escribiríamos el juicio derivado en el ejemplo previo como $\idfunc[\N] (0) \equiv 0$.
\end{notation}

Para introducir funciones de varias variables, podríamos introducir el tipo de productos $A \times B$ y definir $f: (A \times B)\to C$.
Una alternativa equivalente, pero m\'as conveniente, es introducir el uso de funciones ``currificadas"\ (\textit{curried functions}), nombradas as\'i en honor a Haskell Curry \cite{curry_philosophical_1980}.

La currificación de una funci\'on $f: (A\times B) \to C$ es una funci\'on $f': A \to (B \to C)$, de tal forma que si $a:A$ y $b:B$, entonces $f'(a)(b):C$.

\begin{example}\label{const-fst}
    Formaremos una función $A\to(B\to A)$, la cual ignora el valor de la segunda variable, y solo devuelve el valor de la primera variable.
    Sea $\Gamma \defeq A{:}\mathcal{U}, B{:}\mathcal{U}$, tenemos
    \begin{center}
        \AxiomC{$\Gamma$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, x{:} A$ ctx} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, x{:}A, y{:}B$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, x{:}A, y{:}B \vdash x{:}A$}  \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma, x{:}A \vdash \lam{y:B}x : B \to A$} \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma \vdash \lam{x:A}(\lam{y:B}x) :A \to (B \to A)$}  \DisplayProof
    \end{center}
    Poniendo $\Gamma' \defeq A{:}\mathcal{U}, B{:}\mathcal{U}, a{:}A, b{:}B$, el buen comportamiento es mostrado por
    \begin{center}
        \AxiomC{$\Gamma'$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma', x{:} A$ ctx} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma', x{:}A, y{:}B$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma', x{:}A, y{:}B \vdash x:A$}  \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma', x{:}A \vdash \lam{y:B}x: B \to A$}
        \AxiomC{$\Gamma'$} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma' \vdash a:A$} \RightLabel{\footnotesize $\to$-COMP}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma' \vdash \lam{x:A}(\lam{y:B}x)(a) \equiv (\lam{y:B}x)[a/x] : B \to A$}
        \UnaryInfC{$\Gamma' \vdash \lam{x:A}(\lam{y:B}x)(a) \equiv \lam{y:B}a  : B \to A$} \DisplayProof
    \end{center}
    y
    \begin{center}
        \AxiomC{$\Gamma'$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma', y{:}B$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma', y{:}B \vdash a:A$}
        \AxiomC{$\Gamma'$} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma' \vdash b:B$} \RightLabel{\footnotesize $\to$-COMP}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma' \vdash (\lam{y:B}a)(b) \equiv a[b/y] : A$}
        \UnaryInfC{$\Gamma' \vdash (\lam{y:B}a)(b) \equiv a :A$} \DisplayProof
    \end{center}
    Juntando estas dos derivaciones, obtenemos que
    $$\lam{x:A}(\lam{y:B}x)(a)(b) \equiv (\lam{y:B}a)(b) \equiv a$$
\end{example}

\begin{notation}
    Cuando puedan ser inferidas o no sean relevantes, omitiremos también el tipo de las variables dentro de una función lambda. Por ejemplo, escribiríamos $\lam{x:A}\lam{y:B}\Phi$ como $\lamu{x}\lamu{y}\Phi$.

    Si tenemos $f:A_1 \to \cdots \to (A_{n-1} \to A_n)$, escribiremos $f(x_1)(x_2)\cdots(x_n)$ como $f(x_1, x_2, \dots, x_n)$.
    Esto no traerá ambigüedad, puesto que el tipo de $f$ indicará si es una función currificada o una función cuyo dominio es un producto de tipos.
\end{notation}

Una operación común entre funciones es la composición, la siguiente derivación muestra que esta operación efectivamente existe.

\begin{example}\label{comp-nodep}
    Sea $\Gamma \defeq A{:}\mathcal{U}, B{:}\mathcal{U},  C{:}\mathcal{U}$, primero veremos que podemos expandir este contexto adecuadamente; es decir $\Gamma \vdash \Gamma, g{:}B\to C, f{:}A\to B, x{:}A \text{ ctx}$.
    \begin{center}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma \vdash B : \mathcal{U}$ ctx}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma \vdash C : \mathcal{U}$ ctx} \RightLabel{\footnotesize $\to$-FORM}
        \def\defaultHypSeparation{\hskip 2.5em}
        \BinaryInfC{$\Gamma \vdash B\to C: \mathcal{U}$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, (g {:} B\to C)$ ctx}
        \DisplayProof
    \end{center}
    Además,
    \begin{center}
        \AxiomC{$\Gamma, (g{:}B\to C)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (g{:}B\to C) \vdash A : \mathcal{U}$}
        \AxiomC{$\Gamma, (g{:}B\to C)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (g{:}B\to C) \vdash B : \mathcal{U}$} \RightLabel{\footnotesize $\to$-FORM}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma, (g{:}B\to C) \vdash A\to B: \mathcal{U}$}\RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, (g{:}B\to C), (f{:}A\to B)$ ctx}\RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (g{:} B \to C), (f{:} A \to B) \vdash A:\UU$} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$\Gamma, (g{:} B \to C), (f{:} A \to B), (x:A)$ ctx}
        \DisplayProof
    \end{center}
    Ahora, tenemos que
    \begin{center}
        \AxiomC{$\Gamma, (g{:}B\to C), (f{:}A\to B), (x{:}A)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash f: A \to B$} \DisplayProof
    \end{center}
    \begin{center}
        \AxiomC{$\Gamma, (g{:}B\to C), (f{:}A\to B), (x{:}A)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash x: A$}\DisplayProof
    \end{center}
    Juntando estas dos derivaciones, obtenemos
    \begin{center}
        \AxiomC{$\Gamma, \dots, (x{:}A)  \vdash f: A \to B$}
        \AxiomC{$\Gamma, \dots, (x{:}A) \vdash x: A$} \RightLabel{\footnotesize $\to$-ELIM}
        \BinaryInfC{$\Gamma,(g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash f(x) : B$} \RightLabel{\footnotesize $\to$-ELIM} \DisplayProof
    \end{center}
    Similarmente, tenemos que
    \begin{center}
        \AxiomC{$\Gamma, (g{:}B\to C), (f{:}A\to B), (x{:}A)$ ctx} \RightLabel{\footnotesize Vble}
        \UnaryInfC{$\Gamma, (g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash g: B \to C$} \DisplayProof
    \end{center}
    Finalmente, llegamos a
    \begin{center}
        \AxiomC{$\Gamma,\dots, (x{:}A) \vdash g: B \to C$}
        \AxiomC{$\Gamma,\dots, (x{:}A) \vdash f(x) : B$} \RightLabel{\footnotesize $\to$-ELIM}
        \def\defaultHypSeparation{\hskip 3em}
        \BinaryInfC{$\Gamma, (g{:}B\to C), (f{:}A\to B), (x{:}A) \vdash g(f(x)) : C$}   \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma, (g{:}B\to C), (f{:}A\to B) \vdash \lam{x:A}g(f(x)) : A \to C$}   \RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$\Gamma, (g{:}B\to C) \vdash \lamu{f}(\lam{x:A}g(f(x))) : (A \to B) \to (A \to C)$}  \RightLabel{\footnotesize $\to$-INTRO}
            \UnaryInfC{$\Gamma \vdash \lamu{g}\lamu{f}(\lam{x:A}g(f(x))) : (B \to C) \to (A \to B) \to (A \to C)$}  \DisplayProof
    \end{center}
    Esto muestra que la función
    \begin{align*}
        \mathsf{comp}_{A,B,C} & : (B \to C) \to (A \to B) \to (A \to C)                 \\
        \mathsf{comp}_{A,B,C} & \defeq \lam{g:B\to C}\lam{f:A\to B}(\lam{x{:}A}g(f(x)))
    \end{align*}
    existe.
    La prueba de que esta funci\'on se comporta como esperaríamos, es decir que $\mathsf{comp}_{A,B,C}(g,f,x)\equiv g(f(x))$, es semejante a la del Ejemplo \ref{const-fst}, y por lo tanto la omitiremos.

    También se puede verificar el hecho conocido de que la composición es asociativa; es decir, que se tiene
    \[ \mathsf{comp}_{A,C,D}(h, \mathsf{comp}_{A,B,C}(g,f)) \equiv \mathsf{comp}_{A,B,D}(\mathsf{comp}_{B,C,D}(h,g), f)\]
\end{example}

Con esta operaci\'on de composici\'on de funciones entonces obtenemos una categor\'ia.

\begin{definition}
    La categor\'ia $\Type$ tiene como objetos tipos, y como morfismos funciones entre tipos.
    El morfismo identidad asociado a un objeto $A$ est\'a dado por la funci\'on identidad $\idfunc[A]$.
\end{definition}

La \'ultima regla de funciones indica que si formamos una nueva función lambda, que recibe $x$ y devuelve $f(x)$ entonces esta es la misma función que la $f$ original.

\begin{rules}
    (Principio de unicidad para funciones)
    \begin{center}
        \AxiomC{$\Gamma \vdash f : A\to B$} \RightLabel{\footnotesize $\to$-UNIQ}
        \UnaryInfC{$\Gamma \vdash f \equiv (\lam{x :A}f(x)):A \to B$} \DisplayProof
    \end{center}
\end{rules}

N\'otese que esta regla no dice que si tenemos dos funciones $f,g:A \to B$ tales que $f(x)\equiv g(x)$ para todo $x$, entonces $f\equiv g$. Esta propiedad, apropiadamente modificada, ser\'a introducida en la Secci\'on \ref{sec-pathsover-funcs}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de funciones dependientes}
En MC, una pr\'actica com\'un es utilizar sucesiones infinitas de elementos $x_i$ de un conjunto $X$.
Formalmente, esto corresponde a una funci\'on $f : \N \to X$.
Similarmente, a veces es necesario indexar no solo elementos, sino conjuntos con cierta estructura por otros conjuntos.

Por ejemplo, a cada punto $p$ en una variedad $M$, le corresponde su espacio tangente $T_pM$.
Se entiende que esta \'ultima construcci\'on est\'a asociada a cierta funci\'on $g:M \to \bigcup_{p\in M}\{T_pM\}$.
En este \'ultimo caso, es com\'un decir que $\{T_pM\}_{p\in M}$ es una familia de conjuntos indexada por $p \in M$.
Presentamos el constructo an\'alogo en DTT.
\begin{definition}
    Si tenemos que $\Gamma, x:A \vdash B: \UU$, entonces diremos que $B$ es una \textbf{familia de tipos} indexada por $x :A$.
\end{definition}

Recordamos que $B$ no es el car\'acter `$B$', sino una metavariable, por lo que esta puede contener la variable $x$ dentro de s\'i.
Adem\'as, notamos que el requerimiento que $\Gamma, x:A \vdash B: \UU$ es equivalente a que exista una funci\'on $f: A \to \UU$, por lo que en este caso también diremos que $f$ es una familia de tipos.

\begin{example}
    Cada punto $x$ en un espacio topol\'ogico $X$ tiene asociado un grupo, su grupo fundamental.
    Es decir,  $\Gamma, x:X \vdash \pi_1(x,X) : \UU$.
\end{example}

\begin{example}
    Sea $B : \UU$ un tipo, para todo $a:A$, se tiene $\Gamma, a:A \vdash B : \UU$.
    En este caso, decimos que $B$ es una \textbf{familia constante}.
\end{example}

N\'otese que en el caso de familias constantes, una función $f:A\to B$ asigna a cada $a:A$ un elemento $f(a): B$.
Esto se puede generalizar para familias arbitrarias.

\begin{example}
    Sea $X$ un espacio topol\'ogico, para cada $x:X$ podemos escoger un elemento de $\pi_1(x,X) : \UU$, el elemento neutro de ese grupo $0_{\pi_1(x,X)}$.
\end{example}

En este \'ultimo ejemplo tenemos una regla de correspondencia, por lo que se esperar\'ia que podamos formar una función $f$ con el tipo $X \to \pi_1(x,X)$.
Sin embargo, este tipo previo no est\'a bien tipado, pues el $x$ que aparece en el codominio no est\'a definido.
El problema es que el codominio depende del $x:X$ escogido en el dominio, para estos casos necesitaremos el tipo de \textbf{funciones dependientes} de $A$ en $B$, denotado por $\tprd{x:A} B$.

\begin{rules}
    (Reglas de formación de funciones dependientes)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \mathcal{U}_i$}
        \AxiomC{$\Gamma, x:A \vdash B : \mathcal{U}_i$} \RightLabel{\footnotesize $\Pi$-FORM}
        \BinaryInfC{$\Gamma \vdash \tprd{x:A} B : \mathcal{U}_i$} \DisplayProof  \\[.8em]
        \AxiomC{$\Gamma, x:A \vdash b :B$}  \RightLabel{\footnotesize $\Pi$-INTRO}
        \UnaryInfC{$\Gamma \vdash \lam{x:A}b : \tprd{x:A} B$}  \DisplayProof
    \end{center}
    donde la expresi\'on $\tprd{x:A} B$ liga a $x$ hasta el final de esta.
\end{rules}

Con estas reglas, se puede definir el tipo $\tprd{x:X}\pi_1(x,X)$, y una de las funciones pertenecientes a este tipo ser\'ia $\lam{x:X}0_{\pi_1(x,X)}$.

Igual que en el caso de funciones no dependientes, tenemos reglas que nos indican el proceso de aplicación de estas funciones, as\'i como un principio de unicidad.

\begin{rules}
    (Reglas de aplicación de funciones)
    \begin{center}
        \AxiomC{$\Gamma \vdash f : \tprd{x:A} B$}
        \AxiomC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\Pi$-ELIM}
        \BinaryInfC{$\Gamma \vdash f(a) : B[a/x]$} \DisplayProof  \\[.8em]
        \AxiomC{$\Gamma, x:A \vdash b: B$}
        \AxiomC{$\Gamma \vdash a:A$} \RightLabel{\footnotesize $\Pi$-COMP}
        \BinaryInfC{$\Gamma \vdash (\lam{x:A}b)(a) \equiv b[a/x] : B[a/x]$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash f : \tprd{x:A} B$} \RightLabel{\footnotesize $\Pi$-UNIQ}
        \UnaryInfC{$\Gamma \vdash f \equiv (\lam{x :A}f(x)):\tprd{x:A} B$} \DisplayProof
    \end{center}
\end{rules}

Notamos que estas reglas son generalizaciones directas de las reglas de funciones introducidas en la sección anterior.
En efecto, tomaremos estas como las reglas oficiales y definiremos el tipo $A \to B$ como $\tprd{x:A}B$; puesto que en este caso $B$ es una familia constante, y se tiene que $B[a/x]$ es $B$, con lo que se obtienen las reglas originales.

\begin{notation}
    Las variables ligadas por $\Pi$ tienen menor precedencia que otros operadores dentro de un tipo, por lo que $\tprd{x:A}B \to C$ se entiende como $\tprd{x:A}(B \to C)$, por ejemplo.
    Adem\'as, para acentuar el \'enfasis de la (posible) dependencia de $B$ sobre $x$, escribiremos $\tprd{x:A} B(x)$, entendiendo por esto como simplemente $\tprd{x:A} B$.
    Finalmente, mencionamos que existe otra notación alternativa para $\tprd{x:A} B(x)$, como
    $$\prd{x:A} B(x) \hspace{1em} \text{ y } \hspace{1em} \Pi(x:A), B(x).$$
\end{notation}

El uso del s\'imbolo $\Pi$ sugiere que este tipo puede ser interpretado también como el producto cartesiano de lo $B_i$, como lo muestra el pr\'oximo ejemplo.
La siguiente discusi\'on es informal, y utilizaremos algunos t\'erminos de teor\'ia de conjuntos para ayudar la exposici\'on.
Sin embargo, estas nociones no est\'an definidas para DTT en este punto.

\begin{example}
    \label{piexample}
    Sea $A$ un tipo con tres elementos $a_1, a_2, a_3$ y sean $X, Y, Z$ tres tipos con $m,n$ y $p$ elementos respectivamente.
    Podemos asignar al elemento $a_1$ el tipo $X$, al elemento $a_2$ el tipo $Y$ y al elemento $a_3$ el tipo $Z$. Esto nos da una familia de tipos $B: A \to \UU$.

    Una función $f:\tprd{x:A}B$ asigna a cada $x:A$ un elemento de $B(x)$.
    \begin{center}
        \begin{tabular}{ c c c }
            $x:A$ &  & $B(x)$                                      \\ \hline
            $a_1$ &  & $B(a_1)\equiv X \equiv \{x_1, \dots, x_m\}$ \\
            $a_2$ &  & $B(a_2)\equiv Y \equiv \{y_1, \dots, y_n\}$ \\
            $a_3$ &  & $B(a_3)\equiv Z \equiv \{z_1, \dots, z_p\}$
        \end{tabular}
    \end{center}

    Definamos la funci\'on $f_{i,j,k}:\prd{x:A}B(x)$ por $f(a_1)=x_i,f(b_1)=y_j,f(a_3)=z_k$ donde $ 1\leq i\leq m,\,\,i\leq j\leq n,\,\, 1\leq k\leq p $.
    De esta forma, vemos que los elementos de $\tprd{x:A}B(x)$ corresponden exactamente a triples $(x,y,z)$ con $x:X,y:Y$ y $z:Z$.

    As\'i, el n\'umero de funciones en $\tprd{x:A}B(x)$, es el n\'umero de elecciones posibles para cada $a_i$, es decir
    $$ \left| \prd{x:A}B(x)\right| = \prod_{x:A}|B(x)| = |X|\cdot|Y|\cdot|Z|$$
    El hecho de que $|A \to B|=|B|^{|A|}$ es un caso particular de esto.
\end{example}

Una peque\~na limitaci\'on de la función $\idfunc[A]:A \to A$ es que est\'a definida solo para el tipo $A$.
Formalmente, tendr\'iamos que crear una nueva función $\idfunc[T]$ para cada tipo $T$.
Las funciones dependientes evitan la repetici\'on de este proceso.

\begin{example}
    Existe una función $\mathsf{id}$ que asigna a cada $A: \UU$, su función identidad $\idfunc[A]: A \to A$.
    \begin{center}
        \AxiomC{$A:\UU$ ctx} \RightLabel{\footnotesize ctx-Ext}
        \UnaryInfC{$A:\UU, x:A$ ctx}\RightLabel{\footnotesize Vble}
        \UnaryInfC{$A:\UU, x:A \vdash x:A$}\RightLabel{\footnotesize $\to$-INTRO}
        \UnaryInfC{$A:\UU \vdash \lam{x:A}x : A\to A$}\RightLabel{\footnotesize $\Pi$-INTRO}
        \UnaryInfC{$\cdot \vdash \lam{A:\UU}\lam{x:A}x: \prd{A:\UU}A \to A$} \DisplayProof
    \end{center}
    La derivaci\'on de su buen comportamiento es similar al Ejemplo \ref{const-fst}, y ser\'a omitida.
\end{example}

Dados estos últimos ejemplos, vemos que dada una función lambda bien tipada, es un proceso simple (pero tedioso) generar la derivación de su existencia y buen comportamiento.
Por este motivo, en las secciones siguientes comenzaremos a escribir solamente la función lambda, omitiendo las derivaciones asociadas.

\begin{notation}
    Es común en MC definir funciones a partir de reglas de correspondencia; es decir, definiendo $f$ por su comportamiento en un $x$ arbitrario.
    Utilizaremos esta misma pr\'actica, entendiendo estas definiciones como una abreviación de funciones lambda.
    Por ejemplo, la definici\'on de la función
    \begin{gather*}
        \idfunc  :\prd{A:\UU}A\to A \\
        \idfunc  \defeq \lam{A:\UU}\lam{x:A}x
    \end{gather*}
    Puede ser reescrita simplemente como
    \begin{gather*}
        \idfunc         :\prd{A:\UU}A\to A \\
        \idfunc  (A,x)  \defeq x
    \end{gather*}
    Finalmente, para funciones currificadas de varios par\'ametros, se asociaran aplicaciones repetidas de `$\to$' por la derecha, por lo que $A \to B \to C$ se entiende como $A \to (B \to C)$, por ejemplo.
    Todos los dem\'as constructos por introducir asociar\'an hacia la izquierda, de tal forma que $A \times B \times C$ es $(A \times B) \times C$.
\end{notation}

\begin{example}
    Existe una función $\mathsf{swap}$ que invierte el orden de las variables de una función de dos parámetros.
    \[ \mathsf{swap}: \prd{A:\UU}\prd{B:\UU}\prd{C:\UU} (A \to B \to C) \to (B \to A \to C)\]
    Y esta est\'a definida por
    \[ \mathsf{swap}(A,B,C,f) \defeq \lam{b:B}\lam{a:A} f(a,b) \]
    Notamos que de acuerdo a la notación anterior, esta también pudo haber sido definido como:
    \[ \mathsf{swap}(A,B,C,f,b,a)\defeq f(a,b) \]
\end{example}

Como se esperaría, podemos generalizar la definici\'on de composici\'on de funciones del Ejemplo \ref{comp-nodep}.
\begin{definition}
    Podemos definir la funci\'on de composici\'on de funciones
    \[ \mathsf{comp}^* \defeq \prd{A:\UU} \prd{B:\UU} \prd{(C:B \to \UU)} \left( \prd{y:B}C(y) \right) \to \prd{f:A\to B} \prd{x:X} C(f (x )) \]
    dada por
    \[ \mathsf{comp}^*(A,B,C,g,f,x) \defeq g (f (x)) \]
    Esta funci\'on generaliza a la funci\'on del Ejemplo \ref{comp-nodep}, en el sentido de que
    \[ \mathsf{comp}_{A,B,C}(g,f) \jdeq \mathsf{comp}^*(A,B,C,g,f) \]
    Como es usual, escribiremos $g \circ f$ en vez de $\mathsf{comp}^*(A,B,C,g,f)$, dejando los tipos $A$, $B$ y $C$ impl\'icitos.
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de pares dependientes}
As\'i como el tipo de funciones $A \to B$ es un caso particular del tipo de funciones dependientes $\tprd{x:A} B(x)$, el tipo de pares $A \times B$ es un caso particular del tipo de pares dependientes $\tsm{x:A}B$ donde $B$ puede depender de $x:A$.

Intuitivamente, dados dos elementos $a:A$ y $b:B(a)$ es posible generar el par $(a,b)$. Las siguientes reglas formalizan esto\footnote{El uso del tipo de funciones en estas reglas podr\'ia hacer parecer que estas tienen un rol m\'as fundamental que el de pares dependientes; sin embargo, es posible formalizar estas reglas sin hacer menci\'on a las funciones, ver \cite[Ap\'endice A.2.]{the_univalent_foundations_program_homotopy_2013} }.

\begin{rules}
    (Reglas de formación de pares dependientes)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \mathcal{U}_i$}
        \AxiomC{$\Gamma \vdash B : A \to \mathcal{U}_i$} \RightLabel{\footnotesize $\Sigma$-FORM}
        \BinaryInfC{$\Gamma \vdash \tsm{x:A} B : \mathcal{U}_i$} \DisplayProof  \\[.8em]
        \AxiomC{$\Gamma \vdash B : A \to \mathcal{U}_i$}
        \AxiomC{$\Gamma \vdash a:A$}
        \AxiomC{$\Gamma \vdash b:B(a)$}  \RightLabel{\footnotesize $\Sigma$-INTRO}
        \TrinaryInfC{$\Gamma \vdash (a,b) : \tsm{x:A} B$}  \DisplayProof
    \end{center}
    donde la expresi\'on $\tsm{x:A} B$ liga a $x$ hasta el final de esta.
\end{rules}

\begin{notation}
    En caso $B$ sea una familia constante, escribiremos también $A \times B$ en vez de $\tsm{x:A} B$.
    Los variables ligadas por $\Sigma$ tienen menor precedencia que otros operadores dentro de un tipo, por lo que $\tsm{x:A}B \to C$ se entiende como $\tsm{x:A}(B \to C)$, por ejemplo.

    En el caso del producto `$\times$', este tiene mayor precedencia que `$\to$', por lo que $A\times B \to C$ se interpreta como $(A\times B) \to C$. Lo mismo aplica para el coproducto `$+$' definido en la pr\'oxima sección.

    Adem\'as, para acentuar el \'enfasis de la (posible) dependencia de $B$ sobre $x$, escribiremos $\tsm{x:A} B(x)$, entendiendo por esto como simplemente $\tsm{x:A} B$.
    Finalmente, mencionamos que existe otra notación alternativa para $\tsm{x:A} B(x)$, como
    $$\sm{x:A} B(x) \hspace{1em} \text{ y } \hspace{1em} \Sigma(x:A), B(x).$$
\end{notation}

Similarmente al caso de funciones dependientes, el uso del símbolo $\Sigma$ sugiere que este tipo puede ser interpretado también como una suma (disjunta) de los $B_i$, como lo muestra el próximo ejemplo informal.

\begin{example}
    Sea $A = \{a_1, a_2, a_3\}$ y sean $X, Y, Z, B$ como en el Ejemplo \ref{piexample}.
    El tipo de pares dependientes $\tsm{x:A}B$ contiene pares $(a,b)$ con $a:A$ y $b:B(a)$.
    Por ejemplo, podemos definir un par $(a_1, x_i):\tsm{x:A}B$.

    De esta forma, los elementos de $\tsm{x:A}B$ corresponden exactamente a elementos de la unión disjunta de los elementos de $X,Y$ y $Z$.
    En efecto, tenemos
    $$ \left| \tsm{x:A}B\right| = \Sigma_{x:A}|B(x)| = |X| + |Y| + |Z|$$
\end{example}

Las reglas previas solo muestran c\'omo formar pares, para que estos sean \'utiles es necesario ver c\'omo se pueden usar; es decir, c\'omo formar funciones cuyo dominio sea un tipo de pares dependientes.
\begin{rules}
    (Reglas de eliminación de pares dependientes.)
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: (\tsm{x:A} B) \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash g : \tprd{a:A} \tprd{b:B(a)} C((a,b))$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash p : \tsm{x:A}B$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\Sigma$-ELIM}}
        \TrinaryInfC{$\Gamma \vdash \ind{\tsm{x:A} B}^{C,g,p}: C(p)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: (\tsm{x:A} B) \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash g : \tprd{a:A} \tprd{b:B(a)} C(a,b)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash a:A \hspace{2em} \Gamma \vdash b : B[a/x]$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\Sigma$-COMP}}
        \TrinaryInfC{$\Gamma \vdash \ind{\tsm{x:A} B}^{C,g,(a,b)} \jdeq g(a)(b) : C((a,b))$}
        \DisplayProof
    \end{center}
\end{rules}

Aqu\'i, $\ind{\tsm{x:A}B}^{C,g,p}$ es un \textit{primitivo}, un elemento que afirmamos existe, y es un elemento de $C(p)$.
En otras palabras, para cada $C$, $g$ y $p$ que satisfagan los requisitos de la regla, $\Sigma$-ELIM indica que exite este primitivo, el cual depende de estas tres metavariables.
Similarmente para la regla $\Sigma$-COMP.

Estas dos reglas nos dan el siguiente principio de inducción para pares dependientes.

\begin{theorem}
    Sea $A$ un tipo, $B:A \to \UU$ una familia de tipos sobre $A$, entonces existe una función
    \[
        \ind{\sm{x:A}B(x)} :
        \dprd{C:(\sm{x:A} B(x)) \to \UU}
        \Parens{\tprd{a:A}{b:B(a)} C(\tup{a}{b})}
        \to \dprd{p : \sm{x:A}B(x)} C(p)
    \]
    tal que
    $$\ind{\tsm{x:A}B(x)} (C,g,(a,b))\jdeq g(a)(b) : C((a,b))$$
\end{theorem}

\begin{proof}
    Definimos la funci\'on por
    \[ \ind{\sm{x:A}B(x)}(C,g,p) \defeq \ind{\tsm{x:A}B}^{C,g,p} : C(p), \]
    el cual existe por la regla $\Sigma$-ELIM, mientras que la regla $\Sigma$-COMP nos indica que se comporta apropiadamente en pares.
\end{proof}

El principio de inducción para pares dependientes captura la adjunci\'on Hom (Ejemplo \ref{tensor-hom}):
$$ \text{Hom}(A \times B, C) \cong \text{Hom}(A,\text{Hom}(B,C))$$
En efecto, es esta equivalencia la que aprovechamos para nuestra definición de funciones currificadas.

Veamos como podemos utilizar este principio para mostrar la existencia de las funciones de proyección en cada uno de las coordenadas.

\begin{theorem}
    Sea $A$ un tipo y $B$ una familia de tipos sobre $A$. Entonces existen funciones $\fst$ y $\snd$ tales que $\fst(a,b)=a$ y $\snd(a,b)=b$.
\end{theorem}

\begin{proof}
    Sean
    \begin{gather*}
        C\defeq \lam{p}A : \sm{x:A}B(x) \to \UU \\
        g \defeq \lam{x}\lam{y}x : \prd{a:A} \prd{b:B(a)}A
    \end{gather*}
    Notando que $C((a,b)) \equiv A$, y aplicando el principio de inducción obtenemos
    \begin{gather*}
        \fst \defeq \ind{\tsm{x:A}B(x)}(C,g): \prd{p: \sm{x:A} B(x)}A\\
        \fst(a,b)\equiv \ind{\tsm{x:A}B(x)}(C,g,(a,b)) \equiv g(a)(b) \equiv a
    \end{gather*}
    De manera similar, tomando
    \begin{gather*}
        C' \defeq \lam{p} B(\fst(p)) : \sm{x:A} B(x) \to \UU \\
        g' \defeq \lam{x}\lam{y}y : \prd{a:A} \prd{b:B(a)}B(a)
    \end{gather*}
    y notando que $C((a,b)) \equiv B(\fst((a,b)))\equiv B(a)$, aplicando el principio de inducción obtenemos
    \begin{gather*}
        \snd \defeq \ind{\tsm{x:A}B(x)}(C',g'): \prd{p: \sm{x:A} B(x)}B(\fst(p))\\
        \snd \equiv \ind{\tsm{x:A}B(x)}(C',g',(a,b)) \equiv g'(a,b) \equiv b
    \end{gather*}
    Por lo que ambas proyecciones existen.
\end{proof}

Aplicar directamente el principio de inducción requiere cierto nivel de cuidado, en MC cl\'asica definir\'iamos la función $\snd$ simplemente como $\snd((a,b))\defeq b$.
Veremos que esta pr\'actica también se puede realizar en DTT.

\begin{notation}
    (B\'usqueda de patrones para pares dependientes)\\
    Sea $A$ un tipo, $B:A \to \UU$ una familia de tipos sobre $A$ y $C: (\tsm{x:A}B(x)) \to \UU$.
    Podemos definir una función $f : \tprd{p:\tsm{x:A} B(x)}C(p)$ por
    $$f((a,b)) \defeq \Phi$$
    donde $\Phi : C((a,b))$ es una expresión que puede contener $a$ o $b$.
\end{notation}

\begin{justification}
    Dados $a:A$, $b:B(a)$ y $\Phi: C((a,b))$, podemos definir
    $$g\defeq \lam{a:A}\lam{b:B(a)}\Phi : \prd{a:A} \prd{b:B(a)}C((a,b))$$
    Entonces,
    $$f \defeq \ind{\tsm{x:A}B(x)}(C,g): \prd{p: \sm{x:A} B(x)}C(p)$$
    es tal que $f((a,b))\jdeq \Phi$.
\end{justification}

Esto justifica el hecho ``obvio'' de que basta definir una función en un par arbitrario para que la función est\'e bien definida en todo el tipo de pares dependientes.

\begin{notation}
    Omitiremos a veces los paréntesis de un par cuando estos est\'en dentro de una aplicación de una función o dentro de otro par. Por ejemplo, escribiremos $C(a,b)$ en vez de $C((a,b))$, y $(a, b,c)$ en vez de $(a, (b,c))$ o $((a,b),c)$.
\end{notation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\emptyt, \unit, \bool y el tipo del coproducto}
\subsection*{El tipo \emptyt}
El tipo $\emptyt:\UU$ representa el tipo vac\'io, por lo que si obtuvi\'esemos un elemento de \'el, esto ser\'ia un absurdo, y podr\'iamos concluir cualquier cosa. Las siguientes reglas capturan esta intuici\'on.
\newpage

\begin{rules}
    (Reglas del tipo \emptyt.)
    \begin{center}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\emptyt$-FORM}
        \UnaryInfC{$\Gamma \vdash \emptyt : \UU_0$} \DisplayProof \hspace{.8em}
        \AxiomC{$\Gamma \vdash C : \emptyt \to \UU_0$}
        \AxiomC{$\Gamma \vdash z : \emptyt$} \RightLabel{\footnotesize $\emptyt$-ELIM}
        \BinaryInfC{$\Gamma \vdash \ind{\emptyt}^{C,z} : C(z)$}  \DisplayProof
    \end{center}
\end{rules}

Aqu\'i, al igual que para el caso de los pares dependientes, $\ind{\emptyt}^{C,z}$ es un primitivo, el cual afirmamos que existe siempre que se satisfagan las condiciones necesarias. Esto mismo aplica para los elementos $\ind{\unit}^{C,c,a}$, $\inl_{A+B}^a$ y $\inr_{A+B}^b$ introducidos posteriormente en esta secci\'on.

El principio de inducción del $\emptyt$ implica que, dado un $z:\emptyt$, podemos generar un elemento de un tipo que (posiblemente) depende de $z$.

\begin{theorem}
    Existe una función
    \[ \ind{\emptyt} : \prd{C:\emptyt \to \UU}{z:\emptyt} C(z) \]
\end{theorem}

\begin{proof}
    Definimos la funci\'on por
    \[ \ind{\empty}(C,z)\defeq \ind{\emptyt}^{C,z}. \]
\end{proof}

N\'otese que, en particular, el principio de inducci\'on del tipo $\emptyt$ nos da una funci\'on $\rec{\emptyt}(C):\emptyt \to C$, para todo tipo $C$. En efecto, podemos definir
\[ \rec{\emptyt}(C,x) \defeq \ind{\emptyt} (\lamu{x} C,x) \]
Esto nos da indicios de que el tipo $\emptyt$ es un objeto inicial de la categor\'ia $\Type$, y este es efectivamente el caso; pero la demostraci\'on de la unicidad de la funci\'on $\rec{\emptyt}(C)$ tendr\'a que esperar (ver Proposici\'on \ref{0-initial}).

\subsection*{El tipo \unit}

De manera an\'aloga, el tipo $\unit:\UU$ representa el tipo con un solo elemento $\ttt$, por lo que para generar una función con dominio es suficiente definirla en $\ttt$.
Las siguientes reglas dicen precisamente esto.

\begin{rules}
    (Reglas del tipo \unit.)
    \begin{center}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\unit$-FORM}
        \UnaryInfC{$\Gamma \vdash \unit : \UU_i$} \DisplayProof \hspace{.8em}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\unit$-INTRO}
        \UnaryInfC{$\Gamma \vdash \ttt : \unit$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash C : \unit \to \UU_i$}
        \AxiomC{$\Gamma \vdash c : C(\ttt)$}
        \AxiomC{$\Gamma \vdash a : \unit$} \RightLabel{\footnotesize $\unit$-ELIM}
        \TrinaryInfC{$\Gamma \vdash \ind{\unit}^{C,c,a} : C(a)$}  \DisplayProof\\[.8em]
        \AxiomC{$\Gamma \vdash C : \unit \to \UU_i$}
        \AxiomC{$\Gamma \vdash c : C(\ttt)$}\RightLabel{\footnotesize $\unit$-COMP}
        \BinaryInfC{$\Gamma \vdash \ind{\unit}^{C,c,\ttt} \jdeq c : C(\ttt)$}  \DisplayProof
    \end{center}
\end{rules}

El principio de inducción para $\unit$ es el siguiente.

\begin{theorem}
    Existe una función
    \[ \ind{\unit} : \prd{C:\unit \to \UU} C(\ttt) \to \prd{x:\unit}C(x)\]
    tal que
    \[ \ind{\unit}(C,c,\ttt) \defeq c. \]
\end{theorem}

\begin{proof}
    La funci\'on definida por
    \[ \ind{\unit}(C,c,a)\defeq \ind{\unit}^{C,c,a} \]
    cumple los requisitos
\end{proof}
El principio de inducción del $\unit$ nos permite usar la siguiente notación.

\begin{notation}
    (B\'usqueda de patrones para \unit)\\
    Sea $C:\unit \to \UU$ una familia de tipos sobre $\unit$.
    Podemos definir una función $f : \tprd{x:\unit}C(x)$ por
    $$f(\ttt) \defeq \Phi$$
    donde $\Phi : C(\ttt)$.
\end{notation}

\begin{justification}
    Dado $\Phi: C(\ttt)$, podemos definir
    $$f \defeq \ind{\unit}(C,\Phi): \prd{x: \unit}C(x)$$
    y este cumple que $f(\ttt)\jdeq \Phi$.
\end{justification}

Categ\'oricamente, el tipo $\unit$ es un objeto terminal de $\Type$, pues dado un tipo $C$ arbitrario, podemos definir una funci\'on $!\unit_{C}: C \to \unit$ por
\[ !\unit_{C} \defeq \lam{x:C}\star \]
Verificaremos que esta funci\'on es \'unica en la Proposici\'on \ref{1-terminal}.

\subsection*{El tipo \bool y el tipo del coproducto}

Podr\'iamos ahora esperar poder definir $\bool$, el tipo con dos elementos, como la uni\'on disjunta de $\unit$ consigo mismo, a través de una un producto $\bool \defeq X \times \unit$, donde $X$ tiene dos elementos.
Esto es posible, pero no tenemos ning\'un $X$ que satisfaga esta propiedad.

Una alternativa es usando la noción del coproducto.
Dados dos tipos $A$ y $B$, su coproducto es denotado por $A+B$. Este puede ser entendido como una uni\'on disjunta de los dos tipos.
\newpage

\begin{rules}
    (Reglas de formación del coproducto.)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \UU_i$ }
        \AxiomC{$\Gamma \vdash B : \UU_i$ } \RightLabel{\footnotesize $+$-FORM}
        \BinaryInfC{$\Gamma \vdash A+B : \UU_i$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash A : \UU_i$ }
        \AxiomC{$\Gamma \vdash B : \UU_i$ }
        \AxiomC{$\Gamma \vdash a : A$ } \RightLabel{\footnotesize $+$-INTRO$_1$}
        \TrinaryInfC{$\Gamma \vdash \inl_{A+B}(a) : A+B$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash A : \UU_i$ }
        \AxiomC{$\Gamma \vdash B : \UU_i$ }
        \AxiomC{$\Gamma \vdash b: B$ } \RightLabel{\footnotesize $+$-INTRO$_2$}
        \TrinaryInfC{$\Gamma \vdash \inr_{A+B}(b) : A+B$} \DisplayProof
    \end{center}
\end{rules}

De esta forma, $\inl_{A+B}$ y $\inr_{A+B}$ act\'uan como las inyecciones naturales hacia el coproducto.
As\'i, podemos definir $\bool \defeq \unit + \unit$, y este posee dos elementos $\inl(\ttt)$ e $\inr(\ttt)$.

Sin embargo, para poder utilizar un coproducto, debemos saber c\'omo definir funciones cuyo dominio sean estos.\\

\begin{rules} \label{coprodelim}
    (Reglas de eliminación del coproducto.)
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma  \vdash  C :A+B \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{x:A}C(\inl(x))$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash d: \tprd{y:B}C(\inr(y)) \hspace{2em} \Gamma \vdash e : A+B$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$+$-ELIM}}
        \TrinaryInfC{$\Gamma \vdash \ind{A+B}^{C,c,d,e} : C(e)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma  \vdash  C :A+B \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{x:A}C(\inl(x))$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash d: \tprd{y:B}C(\inr(y)) \hspace{2em} \Gamma \vdash a : A$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$+$-COMP$_1$}}
        \TrinaryInfC{$\Gamma \vdash \ind{A+B}^{C,c,d,\inl(a)} \jdeq c(a) : C(\inl(a))$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma  \vdash  C :A+B \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{x:A}C(\inl(x))$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash d: \tprd{y:B}C(\inr(y)) \hspace{2em} \Gamma \vdash b : B$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$+$-COMP$_2$}}
        \TrinaryInfC{$\Gamma \vdash \ind{A+B}^{C,c,d,\inr(b)} \jdeq d(b): C(\inr(b))$}
        \DisplayProof
    \end{center}
\end{rules}

Estas reglas justifican el hecho de que basta definir una función en $A$ y en $B$ para que est\'e definida en $A+B$.
Esto es el principio de inducción para el coproducto.

\begin{theorem}
    Sean $A$ y $B$ tipos. Entonces existe una función
    \[
        \ind{A+B} :
        \dprd{C: (A + B) \to \UU}
        \Parens{\tprd{x:A} C(\inl(x))} \to
        \Parens{\tprd{y:B} C(\inr(y))} \to \tprd{e:A+B}C(e)
    \]
    tal que
    \begin{gather*}
        \ind{A+ B} (C,c,d,\inl(a)) \jdeq c(a) : C(\inl(a)) \\
        \ind{A+ B} (C,c,d,\inr(b)) \jdeq d(b) : C(\inl(b))
    \end{gather*}
\end{theorem}

\begin{proof}
    La funci\'on definida por
    \[ \ind{A+B} (C,c,d,e) \defeq \ind{A+B}^{C,c,d,e} \]
    satisface los requisitos.
\end{proof}

Como en los tipos previos, podemos simplificar considerablemente la notación realizando una b\'usqueda de patrones.

\begin{notation}
    (B\'usqueda de patrones para el coproducto)\\
    Sean $A, B$ tipos, y $C:A+B \to \UU$ una familia de tipos sobre $A+B$.
    Podemos definir una función $f:\tprd{e:A+B}C(e)$ por
    \begin{gather*}
        f(\inl(a)) \defeq \Phi_{0} \\
        f(\inr(b)) \defeq \Phi_{1}
    \end{gather*}
    donde $\Phi_0 : C(\inl(a))$ y $\Phi_1 : C(\inr(b))$ son expresiones que pueden tener a `$a$' o a `$b$' respectivamente.
\end{notation}

\begin{justification}
    Dados $\Phi_0 : C(\inl(a))$ y $\Phi_1 : C(\inr(b))$, podemos definir
    $$f \defeq \ind{A+B}(C, \lam{a:A}\Phi_0,\lam{b:B}\Phi_1): \prd{e: A+B}C(e)$$
    y esta satisface $f(\inl(a)) \defeq \Phi_{0}$ y $f(\inr(b)) \defeq \Phi_{1}$.
\end{justification}

Analizaremos con m\'as detalle el tipo $\bool \defeq \unit + \unit$.
Escribiendo $\bfalse \defeq \inl(\ttt)$ y $\btrue \defeq \inr(\ttt)$, y por el principio de inducción para el coproducto, vemos que para definir una función $\tprd{x:\bool}C(x)$ es suficiente definir dos funciones $f : \unit \to C(\bfalse)$ y $g : \unit \to C(\btrue)$.
Pero por el principio de inducción de $\unit$, esto es lo mismo que seleccionar dos elementos, uno de $C(\bfalse)$ y otro de $C(\btrue)$.
De esta forma, obtenemos el principio de inducción para $\bool$.

\begin{theorem}
    Sea $C:\bool \to \UU$ una familia de tipos sobre $\bool$. Entonces existe una función
    \[
        \ind{\bool} :
        \dprd{C: \bool \to \UU}
        C(\bfalse) \to
        C(\btrue) \to
        \tprd{x:\bool}C(x)
    \]
    tal que
    \begin{gather*}
        \ind{\bool} (C,c_0,c_1,\bfalse) \jdeq c_0 : C(\bfalse) \\
        \ind{\bool} (C,c_0,c_1,\btrue) \jdeq c_1 : C(\btrue)
    \end{gather*}
\end{theorem}

Sea $C: \bool \to \UU$ definido por $C(\bfalse)\defeq A$ y $C(\btrue)\defeq B$, es intuitivo que $\tsm{x:2}C(x)$ sea equivalente, en cierto sentido, a $A +B$.
Este es efectivamente el caso (ver Cap\'itulo 2), y pudimos tambi\'en haber introducido primero el tipo $\bool$ y definir $A+B$ a partir de este.
Cu\'al es introducido primero no causa ninguna diferencia en los resultados.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de los naturales}
Hemos introducido varios principios de inducci\'on para diferentes tipos.
Veamos que para el tipo de los naturales, su principio de inducci\'on en DTT coincide con el principio usal de MC.
Intuitivamente, el tipo de los naturales consiste del conjunto $\{0,1,2,\dots\}$, pero n\'otese que, a excepción del $0$, todo elemento $m$ puede ser escrito como $n+1$ para algún $n$.
Esto sugiere las siguientes reglas.

\begin{rules}
    (Reglas de formación de \N.)
    \begin{center}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\N$-FORM}
        \UnaryInfC{$\Gamma \vdash \N : \UU_i$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\N$-INTRO$_1$}
        \UnaryInfC{$\Gamma \vdash 0 : \N$} \DisplayProof \hspace{.8em}
        \AxiomC{$\Gamma$ ctx} \RightLabel{\footnotesize $\N$-INTRO$_2$}
        \UnaryInfC{$\Gamma \vdash \suc : \N \to \N$} \DisplayProof \hspace{.8em}
    \end{center}
\end{rules}

Aqu\'i la funci\'on $\suc$ representa la funci\'on sucesor usual.
Ahora, para formar funciones que tengan como dominio el tipo $\N$, necesitamos introducir las reglas de eliminaci\'on.\\

\begin{rules}
    (Reglas de eliminación de \N.)
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: \N \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash c_0 : C(0)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash c_s: \tprd{n:\N}C(n) \to C(\suc(n)) \hspace{2em} \Gamma \vdash n:\N$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\N$-ELIM}}
        \TrinaryInfC{$\Gamma \vdash \ind{\N}^{C,c_0,c_s,n} : C(n)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: \N \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash c_0 : C(0)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash c_s: \tprd{n:\N}C(n) \to C(\suc(n))$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\N$-COMP$_1$}}
        \TrinaryInfC{$\Gamma \vdash \ind{\N}^{C,c_0,c_s,0} \jdeq c_0 : C(n)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma\vdash C: \N \to  \mathcal U_i$}
        \AxiomC{$\Gamma \vdash c_0 : C(0)$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash c_s: \tprd{n:\N}C(n) \to C(\suc(n)) \hspace{2em} \Gamma \vdash n:\N$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$\N$-COMP$_2$}}
        \TrinaryInfC{$\Gamma \vdash \ind{\N}^{C,c_0,c_s,\suc(n)} \jdeq c_s(n,\ind{\N}^{C,c_0,c_s,n}) : C(\suc(n))$}
        \DisplayProof
    \end{center}
\end{rules}

Aqu\'i, nuevamente, $\ind{\N}^{C,c_0,c_s,\suc(n)}$ es un primitivo que pertenece a $C(n)$. Con estas reglas, obtenemos el principio de inducci\'on usual.

\begin{theorem}
    Existe una función
    \[\ind{\nat}  : \dprd{C:\nat\to \UU} C(0) \to \Parens{\tprd{n : \nat} C(n) \to C(\suc(n))} \to \tprd{n : \nat} C(n) \]
    tal que
    \begin{align*}
        \ind{\nat}(C,c_0,c_s,0)       & \defeq c_0,                            \\
        \ind{\nat}(C,c_0,c_s,\suc(n)) & \defeq c_s(n,\ind{\nat}(C,c_0,c_s,n)).
    \end{align*}
\end{theorem}

\begin{proof}
    La funci\'on definida por
    \[\ind{\nat}(C,c_0,c_s,n) \defeq \ind{\nat}^{C,c_0,c_s,n} \]
    cumple los requisitos.
\end{proof}

\begin{notation} (B\'usqueda de patrones para los naturales)\\
    Podemos definir una función con dominio $\N$ a una familia de tipos $C:\N \to \UU$ definiendo su comportamiento en $0$ y $\suc(n)$, es decir
    \begin{gather*}
        f(0) \defeq \Phi_{0} : C(0) \\
        f(\suc(n)) \defeq \Phi_{1} : C(\suc(n))
    \end{gather*}
    donde $n$ y $f(n)$ pueden aparecer en $\Phi_{1}$.
\end{notation}

\begin{justification}
    $f$ puede ser definida como
    \[ f\defeq \ind{\N} (C,\Phi_{0},\lam{n}\lam{r}\Phi_{1}^*)\]
    donde $\Phi_{1}^*$, es $\Phi$ con todas las ocurrencias de $f(n)$ reemplazadas por $r$.
\end{justification}

Definimos los símbolos usuales para los números naturales como aplicaciones repetidas del constructo $\suc$. Es decir $1\defeq \suc(0), \;2\defeq \suc(1), \;3\defeq \suc(2), \dots$.

En el caso en el que la familia $C: \N \to \UU$ es constante, el principio de inducción se convierte en el principio de recursi\'on.

\begin{theorem}
    Existe una funci\'on
    \[ \rec{\N}:\prd{C:\UU}\N \to (\N \to \N) \to (\N \to C) \]
\end{theorem}
\begin{proof}
    Podemos definir $\rec{\N}$ por
    \begin{align*}
        \rec{\N}(C,c,f,0)       & \defeq c : C                    \\
        \rec{\N}(C,c,f,\suc(n)) & \defeq f(\rec{\N}(C,c,f,n)) : C
    \end{align*}
\end{proof}

Es m\'as, para todos los tipos existe un principio de recursi\'on, el cual es simplemente el principio de inducci\'on aplicado a una familia constante, como ya lo vimos para el caso del tipo  $\emptyt$.
Veamos dos aplicaciones de esto.

\begin{example}
    Existe una función $\mathsf{double} : \N \to \N$ tal que duplica el valor su input.
    \begin{align*}
        \mathsf{double}           & :\N \to \N                            \\
        \mathsf{double} (0)       & \defeq 0                              \\
        \mathsf{double} (\suc(n)) & \defeq \suc(\suc(\mathsf{double}(n)))
    \end{align*}
    Por ejemplo,
    \begin{align*}
        \mathsf{double}(2) & \jdeq\mathsf{double}(\suc (\suc (0)))            \\
                           & \jdeq \suc(\suc(\mathsf{double}(\suc (0))))      \\
                           & \jdeq \suc(\suc(\suc(\suc(\mathsf{double}(0))))) \\
                           & \jdeq \suc(\suc(\suc(\suc(0))))                  \\
                           & \jdeq 4
    \end{align*}

\end{example}

La función suma también es definida por recursi\'on
\begin{example}
    \begin{align*}
        \mathsf{add}          & :\N \to \N \to \N                       \\
        \mathsf{add}(0)       & \defeq \idfunc[\N]                      \\
        \mathsf{add}(\suc(n)) & \defeq \lam{m}\suc (\mathsf{add}(n)(m))
    \end{align*}
    A forma de recordatorio que la notación previa es solo una simplificaci\'on, mostramos la definición usando solo el principio de inducción:
    \[ \mathsf{add}\defeq \ind{\N} (\lam{n}(\N \to \N), \idfunc[\N], \lam{n}\lam{g}\lam{m}\suc(g(m))) \]
    Como es com\'un, utilizaremos $a+b$ para referirnos a $\mathsf{add}(a)(b)$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec10
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposiciones como tipos}
En la introducción habíamos mencionado que las proposiciones eran representadas como tipos en DTT.
Comenzaremos analizando cada uno de los constructos lógicos principales en MC.

\begin{itemize}
    \item Para mostrar que se cumple $P \wedge Q$, es suficiente mostrar que se cumplen ambos $P$ y $Q$.
          Podemos entonces considerar una prueba de $P \wedge Q$ como un par de pruebas de $P$ y $Q$.
    \item Para mostrar que se cumple $P \vee Q$, es suficiente mostrar que se cumple alguno de $P$ o $Q$.
          Podemos entonces considerar una prueba de $P \vee Q$ como la unión disjunta de pruebas de $P$ y $Q$.
    \item Para mostrar que se cumple $P \implies Q$, es suficiente mostrar que dado $P$, se puede mostrar que se cumple $Q$.
          Podemos entonces considerar una prueba de $P \implies Q$ como una función que toma una prueba de $P$ y devuelve una prueba de $Q$.
    \item Para mostrar que se cumple $\lnot P$, es suficiente mostrar que si es que tenemos $P$, podemos llegar a una contradicción.
          Podemos entonces considerar una prueba de $\lnot P$ como una función que toma una prueba de $P$ y devuelve una prueba de una contradicción.
    \item Para mostrar que se cumple $\forall x\in A, P(x)$, es suficiente mostrar que, dado un $x$ arbitrario en $A$, se puede mostrar que este satisface $P(x)$.
          Podemos entonces considerar una prueba de $\forall x\in A, P(x)$ como una función que toma cualquier elemento $x \in A$ y devuelve una prueba de $P(x)$.
    \item Para mostrar que se cumple $\exists x \in A, P(x)$, es suficiente mostrar que existe un $a \in A$ tal que $P(a)$.
          Podemos entonces considerar una prueba de $\exists x \in A, P(x)$ como un par, el cual consiste de un elemento $a \in A$ y una prueba de $P(a)$.
\end{itemize}

La interpretaci\'on de estos constructos de esta manera es llamada la \textbf{interpretaci\'on BHK},
debido a los nombres de sus principales proponentes L.\ E.\ J.\ Brouwer, Arend Heyting, y Andrey Kolmogorov.
Notemos su similitud con las reglas de introducción para los tipos que ya hemos introducido.

Por ejemplo, la regla de introducción para el tipo del producto indica que para construir un elemento de $P \times Q$ es suficiente mostrar dos elementos $a:P$ y $b:Q$, y el nuevo elemento construido ser\'ia el par $(a,b)$ de estos.
As\'i, los tipos se interpretan como proposiciones y los elementos de estos tipos se interpretan como pruebas o evidencia de estas proposiciones.
Esta correspondencia entre l\'ogica y tipos es llamada el \textbf{isomorfismo de Curry-Howard}.

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ l l }
            \thickhline
            Matemática Clásica      & Teoría de Tipos Dependientes \\
            \hline
            $A \wedge B$            & $A \times B$                 \\
            $A \vee B$              & $A + B$                      \\
            $A \implies B$          & $A \to B$                    \\
            $A \iff B$              & $(A \to B) \times (B \to A)$ \\
            $\lnot A$               & $A \to \emptyt$              \\
            $\forall x \in A, P(x)$ & $\tprd{x:A} P(x)$            \\
            $\exists x \in A, P(x)$ & $\tsm{x:A} P(x)$             \\
            \thickhline                                            \\[-2.4em]
        \end{tabular}
    \end{center}
    \caption{Isomorfismo de Curry-Howard.}
    \label{table:2}
\end{table}

La correspondencia es relativamente simple por lo que no la explicaremos m\'as a detalle, solo el caso de $\lnot A$ merece una mayor atenci\'on.
En DTT, el $\emptyt$ toma el rol de un absurdo, puesto que su mismo principio de inducci\'on indica que es posible formar una función con cualquier codominio dado un elemento de $\emptyt$.
Por este motivo, interpretamos $A \to \emptyt$ como $\lnot A$.

\begin{definition}
    Diremos que dos tipos $A$ y $B$ son l\'ogicamente equivalentes cuando se tiene $A \iff B$; es decir, tenemos dos funciones $f:A \to B$ y $g:B \to A$, como indicado en el Cuadro \ref{table:2}.
\end{definition}

Veamos algunos ejemplos de l\'ogica proposicional y l\'ogica predicativa.

\begin{example}
    Una de las leyes de Morgan indica que para todo par de proposiciones $A$ y $B$ tenemos
    \[\lnot A \vee \lnot B \implies \lnot (A \wedge B). \]
    El equivalente en DTT es la existencia de una función
    \[f:  \prd{A:\UU}\prd{B:\UU}(A \to \emptyt) + (B \to \emptyt) \to (A \times B \to \emptyt) \]
    En efecto, combinando la b\'usqueda de patrones en el coproducto y en el producto, podemos definir $f$ como
    \begin{gather*}
        f(A,B,\inl (f_1), (a,b)) \defeq f_1(a) \\
        f(A,B,\inr (f_2), (a,b)) \defeq f_2(b)
    \end{gather*}
\end{example}

\begin{notation}
    A veces omitiremos la menci\'on expl\'icita de los $\Pi$ tipos involucrados, cuando estos toman el rol l\'ogico de ``para todo'', entendiendo que el t\'ermino que estamos construyendo es una funci\'on dependiente con un dominio apropiado.
\end{notation}

\begin{example}
    Consideremos la siguiente implicaci\'on usada com\'unmente
    \[ \exists x \in A, \lnot P(x) \implies \lnot (\forall x \in A, P(x)) \]
    Esta es representada por la existencia de una función
    \[ f: \tsm{x : A} (P(x) \to \emptyt) \to (\tprd{x : A} P(x)) \to \emptyt \]
    Esta puede ser definida por
    \[ f((a, g), h) \defeq g(h(a)) \]
\end{example}

\begin{example}
    El axioma de elección en MC indica que dada una colección de conjuntos no vac\'ios $X$, es posible
    crear una función $f:X \to \bigcup X$ que selecciona un elemento de cada conjunto. Es decir,
    \[ \left( \forall x \in X,  \exists y \in \bigcup X, (y \in x) \right) \implies \left( \exists f: X \to \bigcup X, \forall x \in X, (f(x) \in x) \right) \]
    En DTT, esto podr\'ia ser entendido\footnote{La verdadera formalizaci\'on del axioma de elección como visto de manera cl\'asica, es ligeramente distinta a la presentaci\'on actual, ver \cite[Sección 3.8]{the_univalent_foundations_program_homotopy_2013}.} como un caso particular de
    \[ \ac : \Parens{\tprd{x:A} \tsm{y :B} R(x,y)} \to
        \Parens{\tsm{f:A\to B} \tprd{x:A} R(x,f(x))}
    \]
    Podemos definir esta función como
    \[ \ac(h) \defeq \Parens{ \lamu{x} \fst(h(x)), \lamu{ x} \snd(h(x)) } \]
    Esta función est\'a bien definida puesto que
    \begin{align*}
        \lamu{x:A} \fst(g(x)) & : A \to  B,                   \\
        \lamu{x:A} \snd(g(x)) & : \tprd{x:A} R(x,\fst(g(x))).
    \end{align*}
    como es requerido por el tipo del codomino de $\ac$.
\end{example}

\begin{definition}
    Dado un tipo $A$, si existe un elemento $a$ tal que $a:A$, diremos que $A$ es un tipo \textbf{habitado}.
\end{definition}

As\'i, se dice una proposici\'on $P$ es \textbf{verdadera} cuando es un tipo habitado.
El ejemplo previo muestra que el axioma de elección es verdadero en esta teoría.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec11
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{El tipo de identidades} \label{idtype}
De acuerdo a la interpretación de proposiciones como tipos, deber\'ia haber un tipo que refleje la propiedad de que dos elementos sean iguales.
Es decir, si tenemos $x,y:A$, tenemos un tipo de identidades entre $x$ y $y$, el cual denotamos por $\id[A]{x}{y}$.

\begin{rules}
    (Reglas de formación del tipo de identidades.)
    \begin{center}
        \AxiomC{$\Gamma \vdash A : \UU_i$}
        \AxiomC{$\Gamma \vdash a : A$}
        \AxiomC{$\Gamma \vdash b : A$} \RightLabel{\footnotesize $=$-FORM}
        \TrinaryInfC{$\Gamma \vdash a =_A b : \UU_i$} \DisplayProof \\[.8em]
        \AxiomC{$\Gamma \vdash A : \UU_i$}
        \AxiomC{$\Gamma \vdash a : A$}\RightLabel{\footnotesize $=$-INTRO}
        \BinaryInfC{$\Gamma \vdash \refl{a} : \id[A]{a}{a}$} \DisplayProof
    \end{center}
\end{rules}

Intuitivamente, el tipo $\id[A]{x}{y}$ representa la noción de igualdad, y este est\'a habitado justamente cuando $x$ es igual a $y$.
En particular, $\id[A]{x}{x}$ siempre est\'a habitado, puesto que por $=$-INTRO tenemos una funci\'on
\[ \mathsf{refl} : \prd{x:A} x =_A x, \]
definida por $\mathsf{refl}(x)\defeq \refl{x}$.
Adem\'as, notemos que es imposible formar el tipo de igualdades para dos elementos en dos tipos distintos.


La introducción de este tipo permite enunciar y probar teoremas que involucren la igualdad.

\begin{example}
    Por definición, para todo $n:\N$ tenemos $0+n\defeq n$, por lo que podemos definir
    \[\lam{n}\refl{n}:\prd{n:\N}(0+n=_\N n)\]
    Por otro lado, la demostraci\'on de $\prd{n:\N}(n+0=_{\N} n)$ requiere de otros resultados, como el principio de inducción para el tipo de identidades.
\end{example}

De manera an\'aloga a los casos de la suma dependiente y el coproducto, dado que la forma can\'onica de introducir un elemento del tipo de identidades es por $\refl{x}$, basta definir una función dependiente en estos elementos para que est\'e definida en todo $\id[A]{x}{y}$.
Este razonamiento nos da:

\begin{rules}
    (Reglas de eliminaci\'on del tipo de identidades.)
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma \vdash  C : \tprd{x,y:A}(\id[A]{x}{y}) \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{z:A}C(z,z, \refl{z})$}
        \alwaysNoLine
        \BinaryInfC{$\Gamma \vdash a: A \hspace{2em} \Gamma \vdash b:A \hspace{2em} \Gamma \vdash p: \id[A]{a}{b}$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$=$-ELIM}}
        \TrinaryInfC{$\Gamma \vdash \ind{=_A}^{C,c,a,b,p} : C(a,b,p)$}
        \DisplayProof
    \end{center}
    \begin{center}
        \def\extraVskip{.5pt}
        \AxiomC{\ }
        \AxiomC{$\Gamma \vdash  C : \tprd{x,y:A}(\id[A]{x}{y}) \to \UU_i$}
        \AxiomC{$\Gamma \vdash c: \tprd{z:A}C(z,z, \refl{z})$}
        \alwaysNoLine
        \BinaryInfC{$\hspace{4em}\Gamma \vdash a: A$}
        \AxiomC{\ }
        \def\extraVskip{2pt} \def\ScoreOverhang{-2pt}  \def\defaultHypSeparation{\hskip -1em}
        \alwaysSingleLine \RightLabel{\footnotesize{$=$-COMP}}
        \TrinaryInfC{$\Gamma \vdash \ind{=_A}^{C,c,a,a,\refl{a}} : C(a,a,\refl{a})$}
        \DisplayProof
    \end{center}
\end{rules}

Como en los tipos previos, $\ind{=_A}^{C,c,a,b,p}$ es un primitivo que existe bajo ciertas condiciones, y estas reglas nos dan un principio de introducción y una b\'usqueda de patrones.

\begin{theorem}
    Para todo tipo $A : \UU$, existe una función
    \[
        \indid{A} :  \dprd{C : \prd{x,y:A} (\id[A]{x}{y}) \to \UU}
        \Parens{\tprd{x:A} C(x,x,\refl{x})} \to
        \dprd{x,y:A}{p:\id[A]{x}{y}}   C(x,y,p)
    \]
    tal que
    \[ \indid{A}(C,c,x,x,\refl{x}) \defeq c(x). \]
\end{theorem}

\begin{proof}
    Podemos definir $\indid{A}$ por
    \[ \indid{A}(C,c,x,x,p) \defeq \indid{A}^{C,c,x,x,p}. \]
\end{proof}

\begin{notation}
    (B\'usqueda de patrones para el tipo de identidades)\\
    Podemos definir una función $f : \dprd{x,y:A}{p:\id[A]{x}{y}}   C(x,y,p)$ definiendo su comportamiento en $\refl{x}$, es decir
    \[ f(\refl{x}) \defeq \Phi : C(x,x,\refl{x}) \]
\end{notation}

\begin{justification}
    La funci\'on $f$ puede ser definida como
    \[ f\defeq \indid{A} (C,\lam{x}\Phi)\]
\end{justification}

As\'i, para definir una funci\'on $f : \dprd{x,y:A}{p:\id[A]{x}{y}} C(x,y,p)$ basta asumir que $x$ es $y$, y definir el comportamiento de la funci\'on en los caminos $\refl{x}$.
Utilizaremos esto m\'ultiples veces en los siguientes cap\'itulos.

El tipo de identidades es quiz\'as el que mayor riqueza trae a esta teor\'ia, y el siguiente cap\'itulo estar\'a dedicado principalmente a este.
\begin{notation}
    Escribiremos $x=y$ en vez de $\id[A]{x}{y}$ cuando no haya riesgo de confusión.
\end{notation}

Para diferenciar el tipo $\id[A]{x}{y}$ del juicio $x \jdeq y$, a veces se llama al primero de estos como una \textbf{igualdad proposicional}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec_
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Grupos}
Veamos c\'omo los tipos introducidos nos permiten formalizar en DTT el concepto de un grupo.
Recordemos que en MC un grupo es par $(G, *)$, tal que $G$ es un conjunto y $*$ es una operaci\'on binaria en $G$ tal que
\begin{itemize}
    \item $*$ es asociativa,
    \item existe un elemento neutro $e$, tal que para todo $g \in G$ se tiene que $e * g = g * e = g$, y
    \item para todo $g \in G$ existe un $g^{-1} \in G$ tal que $g*g^{-1}=g^{-1}*g=e$.
\end{itemize}

Esta estructura puede ser reflejada directamente en la siguiente definici\'on
\begin{definition}
    Dado un tipo $A$, diremos que este tiene una \textbf{estructura de grupo} si es que el tipo
    \begin{align*}
        \mathsf{GroupStr}(A) \defeq \sm{m:A\to A \to A} & \prd{x,y,z:A} \left( m(x,m(y,z))=m(m(x,y),z) \right)                \\
        \times                                          & \sm{e:A } \prd{g:A} (m(e, g) = g) \times (m(g , e) = g)             \\
        \times                                          & \sm{i:A \to A} \prd{g:A} (m(g , i(g)) = e) \times (m(i(g),  g) = e)
    \end{align*}
    est\'a habitado.
\end{definition}
Cada l\'inea de la definici\'on previa corresponde a uno de los puntos de la definici\'on cl\'asica.
Con el concepto de estructura ya definido, podemos definir lo que es un grupo.

\begin{definition}\label{Groups}
    Un \textbf{grupo} es un tipo junto con una estructura de grupo. Es decir, un elemento del tipo
    \[ \mathsf{Group} \defeq \sm{A: \UU}\mathsf{GroupStr}(A) \]
\end{definition}

N\'otese que, a diferencia de MC, s\'i tenemos un tipo de todos los grupos, el cual es $\mathsf{Group}$.

Es claro que una formalizaci\'on similar aplica para la gran mayor\'ia de teor\'ias algebraicas, como las de los anillos, m\'odulos, categor\'ias, etc.


%%%% sec12
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metateor\'ia de DTT}
Hemos introducido las reglas de DTT que usaremos en lo que sigue del presente documento.
En la presente sección discutiremos sobre las reglas mismas, y sobre las propiedades de la teor\'ia que estas generan; es decir, la \textit{metateor\'ia}.

En primer lugar, parecer\'ia que existe cierta inconsistencia en algunas reglas. Por ejemplo, consideremos la siguiente regla ya introducida

\begin{center}
    \AxiomC{$\Gamma \vdash a:A$}
    \UnaryInfC{$\Gamma \vdash a\equiv a:A$} \DisplayProof \hspace{2em}
\end{center}

Se tiene $\Gamma \vdash a:A$ en la hipótesis; sin embargo, no estamos afirmando que $A$ sea un tipo, por lo que podr\'ia ser posible que $a:A$ sea una expresión sin sentido.

Esta inquietud, aunque v\'alida, no est\'a justificada, pues tenemos el siguiente resultado.

\begin{theorem}
    Si se tiene {$\Gamma \vdash a:A$} para alg\'un $\Gamma$, también se tiene que $\Gamma \vdash A:\UU_i$.
\end{theorem}

N\'otese que a diferencia de los resultados y ejemplos previos, este resultado es un resultado sobre la teoría misma.
Los teoremas de incompletitud de G\"odel \cite{godel_uber_1931} est\'an en este mismo nivel.

\begin{proof}
    La t\'ecnica a través la cual se muestran este tipo de teoremas en DTT es a través de \textit{inducción estructural}.
    Recordemos que una derivaci\'on de un juicio es en realidad un \'arbol invertido con el juicio por derivar en la ra\'iz del \'arbol.
    Por lo tanto, podemos utilizar inducción en el \'arbol, de acuerdo a la \'ultima regla usada para llegar a $\Gamma \vdash a:A$.

    Por ejemplo, si la \'ultima regla usada fue $\N$-INTRO$_1$, tenemos que $\Gamma \vdash 0:\N$, y por $\N$-FORM sabemos que $\N$ es un tipo.
    Un razonamiento an\'alogo por casos para cada regla relevante concluye la demostraci\'on.
\end{proof}

Otros dos resultados importantes, que ya hemos utilizado libremente en los ejemplos son:

\begin{theorem}(Substituci\'on)
    Si se tiene $\Gamma \vdash a : A$ y $\Gamma , x:A , \Delta \vdash b :B$, entonces es posible derivar $\Gamma, \Delta [a/x] \vdash b[a/x] : B[a/x]$.
\end{theorem}
\begin{theorem}(Debilitaci\'on)
    Si se tiene $\Gamma \vdash A : \UU_i$ y $\Gamma , \Delta \vdash b :B$, entonces es posible derivar $\Gamma, x:A, \Delta \vdash b:B$.
\end{theorem}

La demostración de estos teoremas  para teor\'ias similares se puede encontrar en \cite{pierce_types_2002}, por ejemplo.

El \'ultimo metateorema que presentaremos sobre DTT es que esta teor\'ia es consistente, es decir no se puede derivar una contradicción a partir de las reglas ya introducidas.

\begin{theorem}\label{cons-dtt}(Consistencia de DTT)
    No es posible derivar una contradicción en DTT, es decir $\cdot \vdash x : \emptyt$ para alg\'un $x$; asumiendo que la teor\'ia usual de MC tambi\'en es consistente.
\end{theorem}

Omitimos también la demostración de este resultado, que se puede encontrar en \cite{martin-lof_intuitionistic_1984}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec13
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Comentarios adicionales}
\subsection*{La complejidad de DTT}
La introducción de las reglas y la derivación de juicios podr\'ia hacer parecer que DTT es una teor\'ia mucho m\'as complicada que la l\'ogica cl\'asica; sin embargo, este no es el caso.
La l\'ogica cl\'asica en realidad también est\'a formalizada de una forma similar, por ejemplo se tiene la siguiente regla para la introducción de la conjunci\'on:

\begin{center}
    \AxiomC{$\varphi$}
    \AxiomC{$\psi$} \RightLabel{\footnotesize  $\wedge$-INTRO}
    \BinaryInfC{$\varphi \wedge \psi$}  \DisplayProof
\end{center}

As\'i existen reglas para cada constructo l\'ogico ($\forall, \exists, \wedge, \vee, \neg, \implies$), y resultados an\'alogos a los de la sección previa \cite{chiswell_mathematical_2007}, los cuales son asumidos implicitamente por los matemáticos, raz\'on por la que los omitimos tambi\'en para DTT.

La diferencia es entonces que las reglas de la l\'ogica cl\'asica son usualmente introducidas de manera informal, mientras que hemos decidido presentar las reglas de DTT formalmente en este trabajo.
Diversas presentaciones de DTT introducen los constructos de forma informal, como \cite{nordstrom_programming_1990} y \cite{friedman_little_2018}.

\subsection*{Constructivismo}
La l\'ogica subyacente en DTT es una l\'ogica \textbf{constructiva}, también llamada \textbf{l\'ogica intuicionista}.
Por ejemplo, en esta no es posible demostrar $P \vee \neg P$, la ley del medio excluido.
Es posible a\~nadir esta ley como una regla adicional\footnote{Esto es posible en DTT, pero una vez introducido el axioma de univalencia esto se vuelve inconsistente. En cambio, se puede introducir un axioma similar, que solo involucra proposiciones simples (ver Sección \ref{hprops}).}, pero esto no ser\'a necesario en el desarrollo actual.

Ante cierta inspecci\'on, es f\'acil notar que esta ley es en cierto sentido problem\'atica.
Esta permite afirmar la existencia de objetos que no han sido construidos expl\'icitamente, o simplificar problemas de una forma no obvia. Por ejemplo, consideremos la siguiente proposici\'on:

\begin{proposition}
    Existe un n\'umero natural $n$, tal que $n=0$ si y solo si la hipótesis de Riemann es verdadera.
\end{proposition}

\begin{proof}
    Si la hip\'otesis de Riemann es verdadera, entonces $n$ es 0. Si la hipótesis de Riemann es falsa, entonces podemos poner $n=1$.
\end{proof}

Este n\'umero $n$ refleja la veracidad de la hip\'otesis de Riemann de una forma no obvia.
Por otro lado, si la prueba fuese constructiva, habr\'iamos generado un $n$ espec\'ifico, y podr\'iamos verificar f\'acilmente si este es o no diferente de 0.

No asumir la ley del medio excluido significa que todos los elementos de los cuales tenemos informaci\'on has sido construidos paso a paso, por lo que adem\'as de su existencia, podemos indagar sobre otras propiedades relevantes que pueden tener.

Otro principio relacionado es el de reducci\'on al absurdo, $\neg \neg P \implies P$.
Este es en realidad equivalente a la ley del medio excluido, y permite probar la existencia de elementos sin saber cu\'ales son. Por ejemplo:

\begin{proposition}
    En la expansi\'on decimal de $\pi$, existen dos d\'igitos que se repiten infinitas veces.
\end{proposition}

\begin{proof}
    Si no fuese as\'i, se tendr\'ia que un solo d\'igito se repite infinitas veces, o que ning\'un d\'igito se repite infinitas veces. En ambos casos, concluimos que $\pi$ es un racional, lo cual es un absurdo.
\end{proof}

Sin embargo, en esta prueba no hemos hallado cu\'ales son estos dos d\'igitos; es decir, la prueba no es constructiva.

Esto no quiere decir que no podamos utilizar nunca el razonamiento de $P \vee \lnot P$, solo que para utilizarlo es necesario primeramente demostrar que esto se cumple para el tipo $P$ en cuesti\'on. Realizaremos esto para las igualdades en los naturales en la Secci\'on \ref{natpaths}.

\subsection*{Asistentes de pruebas}

Incluso grandes matemáticos como Leibniz, Gauss, Andrew Wiles, entre otros, han cometido graves errores en sus demostraciones, y ellos no fueron los primeros ni ser\'an los \'ultimos.
A fin de evitar esto, existen los llamados \textbf{asistentes de pruebas}, programas que verifican que una demostración es correcta.
La mayor\'ia de estos usan DTT en vez de teor\'ia de conjuntos, consideremos el siguiente ejemplo tomado de \cite{376973} para ver por qu\'e:

\begin{proposition}
    Sean $U$ y $V$ espacios vectoriales y $f:U \to V$ una función lineal. Entonces $f(2x+y)=2f(x)+f(y)$.
\end{proposition}

La proposici\'on es f\'acilmente entendida por un lector que conozca estos conceptos, y pareciese que se ha presentado con precisión los variables necesarias, pero veamos la gran cantidad de informaci\'on omitida:

\begin{itemize}
    \item Se ha entendido que existe un campo $K$ subyacente a $U$ y a $V$.
    \item Se ha entendido que $f$ es en realidad una función entre los conjuntos subyacentes $f: |U| \to |V|$, recordemos que un espacio vectorial $U$ es un triple $(|U|,\cdot,+)$.
    \item Se ha entendido que $x$ y $y$ son elementos arbitrarios de $|U|$.
    \item Se ha entendido que el `$+$' en la izquierda de la ecuaci\'on es la suma asociada a $U$, mientras que el `$+$' en la derecha es el asociado a $V$.
    \item Finalmente, se ha entendido que $2$ es $1+1$, donde $1$ es el neutro de la multiplicaci\'on del campo $K$.
\end{itemize}

Esta gran cantidad de informaci\'on no puede ser inferida correctamente por computadoras que formalicen la teor\'ia de conjuntos.
Uno de los principales problemas es que la estructura que tiene cierto constructo, como los espacios vectoriales, no es reflejada de una manera \'unica en teor\'ia de conjuntos.
Por poner otro ejemplo, dada la construcci\'on de los reales como cortes de Dedekind, no solo tiene sentido la proposici\'on `$0_\Q \in 1_\R$'; peor a\'un, es verdadera.

En contraste, en DTT, los elementos de un tipo pertenecen a un \'unico tipo (a excepción de los tipos mismos), y la estructura adicional es parte esencial y \'unica de una definición (ver \ref{Groups}, por ejemplo).
Estos hechos permiten la inferencia del significado de variables no completamente especificadas, en la gran mayor\'ia de los casos.
Esto hace que DTT sea una teor\'ia m\'as apropiada para la formalizaci\'on de las matemáticas a trav\'es de programas de computadoras.

Ya existe un gran esfuerzo a nivel global de traducir la matemática cl\'asica al lenguaje de DTT, usado por los asistentes de pruebas, y as\'i permitir la verificaci\'on de estos resultados por computadora.
Entre estos, mencionamos las formalizaciones \cite{mahboubi_mathematical_2021} y \cite{the_mathlib_community_lean_2020}, proyectos con m\'as de 250 contribuidores en conjunto.

Gran parte de resultados que consideramos b\'asicos, y que se ense\~nan a nivel de pregrado ya est\'an formalizados.
Sin embargo, tambi\'en se han verificado algunos resultados m\'as modernos y complicados.
El teorema de Feit-Thompson \cite{1103053943}, que indica que todo grupo de orden finito e impar es soluble, fue verificado usando el programa Coq en el 2013 \cite{ftcoq2013}.

Otro ejemplo es la verificaci\'on de un resultado avanzado de geometr\'ia algebraica de Peter Scholze, ganador del premio Fields 2018, en colaboraci\'on con Dustin Clausen.
El proceso de formalizaci\'on comenz\'o como un reto de Scholze a la comunidad de asistentes de pruebas \cite{scholze_2020}:
\begin{displayquote}
    Considero que este teorema es de una gran importancia fundacional, por lo que estar 99.9\% seguro no es suficiente\ldots\
    Pas\'e mucho del 2019 obsesionado con la prueba de este teorema, casi volvi\'endome loco sobre esta. Al final logramos escribir el argumento en un art\'iculo, pero creo que nadie m\'as se ha atrevido a ver los detalles de este, as\'i que todav\'ia tengo algunas peque\~nas dudas.
\end{displayquote}

Solo 6 meses despu\'es, con la ayuda de varios matem\'aticos y cient\'ificos de la computaci\'on, Scholze escribe que su reto era pr\'acticamente un \'exito: aunque todav\'ia no se hab\'ia demostrado el teorema, todos los lemas que causaban cierta duda ya estaban formalizados \cite{scholze_half_2021}.
A trav\'es de este ejercicio, \'el comenta, no solo encontr\'o m\'ultiples errores (que afortunadamente fueron posibles de solucionar), tambi\'en profundiz\'o el entendimiento de su propia prueba.

Esta es la propuesta de los proponentes de los asistentes de pruebas: introducir a las computadoras como una herramienta m\'as en el arsenal que posee un matem\'atico, y obtener una mejor comprensi\'on del tema de estudio, as\'i como la posibilidad de no volver a equivocarnos nunca m\'as\footnote{Podr\'ia preguntarse uno, ?`qu\'e garantiza que el programa no cometa un error? La respuesta es: matemática. Se puede razonar de una forma similar a la de inducción estructural, y verificar que cada paso del programa es correcto, y por lo tanto, el algoritmo entero.}.

El presente trabajo advoca esta posici\'on, por lo que todos los resultados aqu\'i descritos has sido formalizados en un asistente de pruebas, llamado Agda.
El c\'odigo se encuentra disponible en l\'inea, a trav\'es de la siguiente p\'agina web interactiva \url{https://shiranaiyo.github.io/MastersThesis/}.

Enfatizamos que la posibilidad de la formalizaci\'on en un asistente de pruebas es solo una ventaja m\'as de DTT.
Como mencionamos, la ventaja principal es el tratamiento uniforme de proposiciones y tipos, la cual ser\'a aprovechada en los siguientes cap\'itulos.

\end{document}
